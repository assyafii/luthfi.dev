<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on M. Luthfi As Syafii</title>
        <link>/posts/</link>
        <description>Recent content in Posts on M. Luthfi As Syafii</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sat, 01 Jan 2022 00:00:00 +0000</lastBuildDate>
        <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>1. Install Kubernetes cluster multi Master High Availability</title>
            <link>/posts/install-kubernetes-cluster-multi-master-high-availability/</link>
            <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
            
            <guid>/posts/install-kubernetes-cluster-multi-master-high-availability/</guid>
            <description>Specification : Calico, Containerd, Haproxy, Kubernetes v1.22.x
Lab Topology First, prepare all VM All Nodes except LB Nodes Set mapping hostname nano /etc/hosts Install packages containerd Load overlay and br_netfilter kernal modules.
cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/containerd.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter Set these system configurations for Kubernetes networking cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF Apply settings sudo sysctl --system Install containerd sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y containerd sudo mkdir -p /etc/containerd sudo containerd config default | sudo tee /etc/containerd/config.</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : Calico, Containerd, Haproxy, Kubernetes v1.22.x</p>
</blockquote>
<h3 id="lab-topology"><strong>Lab Topology</strong></h3>
<p><img src="./k8s-topology.png" alt="k8s-topology">
 </p>
<h4 id="first-prepare-all-vm">First, prepare all VM</h4>
<p><img src="./virsh.png" alt="k8s-virsh"></p>
<h3 id="all-nodes-except-lb-nodes"><strong>All Nodes except LB Nodes</strong></h3>
<hr>
<h4 id="set-mapping-hostname">Set mapping hostname</h4>
<pre tabindex="0"><code>nano /etc/hosts
</code></pre><p><img src="./hosts.png" alt="k8s-virsh"></p>
<h4 id="install-packages-containerd">Install packages containerd</h4>
<p>Load overlay and br_netfilter kernal modules.</p>
<pre tabindex="0"><code>cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf 
overlay 
br_netfilter 
EOF
</code></pre><pre tabindex="0"><code>sudo modprobe overlay 
sudo modprobe br_netfilter
</code></pre><h4 id="set-these-system-configurations-for-kubernetes-networking">Set these system configurations for Kubernetes networking</h4>
<pre tabindex="0"><code>cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf 
net.bridge.bridge-nf-call-iptables = 1 
net.ipv4.ip_forward = 1 
net.bridge.bridge-nf-call-ip6tables = 1 
EOF
</code></pre><h4 id="apply-settings">Apply settings</h4>
<pre tabindex="0"><code>sudo sysctl --system
</code></pre><h4 id="install-containerd">Install containerd</h4>
<pre tabindex="0"><code>sudo apt-get update &amp;&amp; sudo apt-get install -y containerd
sudo mkdir -p /etc/containerd
sudo containerd config default | sudo tee /etc/containerd/config.toml
sudo systemctl restart containerd
sudo systemctl enable containerd
</code></pre><h4 id="disable-swap">Disable SWAP</h4>
<pre tabindex="0"><code>sudo swapoff -a
sudo sed -i &#39;/ swap / s/^\(.*\)$/#\1/g&#39; /etc/fstab
</code></pre><h4 id="install-depedency-packages">Install depedency packages</h4>
<pre tabindex="0"><code>sudo apt update &amp;&amp; sudo apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
</code></pre><h4 id="add-kubernetes-repo">add kubernetes repo</h4>
<pre tabindex="0"><code>cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
sudo apt update
</code></pre><h4 id="install-kubectl-kubelet--kubeadm-packages">Install kubectl, kubelet, &amp; kubeadm packages</h4>
<pre tabindex="0"><code>sudo apt-get install -y kubelet=1.22.1-00 kubeadm=1.22.1-00 kubectl=1.22.1-00
sudo apt-mark hold kubelet kubeadm kubectl
</code></pre><p> </p>
<h3 id="all-lb-nodes"><strong>All LB Nodes</strong></h3>
<hr>
<h4 id="install-keepalived--haproxy-packages">Install keepalived &amp; HAproxy packages</h4>
<pre tabindex="0"><code>sudo apt install keepalived haproxy psmisc -y
</code></pre><h4 id="configure-haproxy">Configure HAproxy</h4>
<p>Add HAproxy configuration bellow in last line</p>
<pre tabindex="0"><code>sudo nano /etc/haproxy/haproxy.cfg
</code></pre><pre tabindex="0"><code>frontend kubernetes
        bind *:6443 
        option tcplog
        mode tcp
        default_backend kubernetes-master-nodes

backend kubernetes-master-nodes
        mode tcp
        balance roundrobin
        option tcp-check
        server fi-k8s-master-1 10.20.10.201:6443 check fall 3 rise 2
        server fi-k8s-master-2 10.20.10.202:6443 check fall 3 rise 2
        server fi-k8s-master-3 10.20.10.203:6443 check fall 3 rise 2
</code></pre><h4 id="restart-services">Restart services</h4>
<pre tabindex="0"><code>systemctl restart haproxy.service
systemctl status haproxy.service
systemctl enable haproxy.service
</code></pre><h4 id="configure-keepalived">Configure keepalived</h4>
<pre tabindex="0"><code>sudo nano /etc/keepalived/keepalived.conf
</code></pre><h4 id="haproxy-nodes-1">Haproxy nodes 1</h4>
<pre tabindex="0"><code>global_defs {
   notification_email {
     root@localhost
   }
   notification_email_from root@localhost
   smtp_server localhost
   smtp_connect_timeout 30
}

# Script used to check if HAProxy is running
vrrp_script check_haproxy {
    script &#34;killall -0 haproxy&#34;
    interval 2 
    weight 2
}

vrrp_instance VI_1 {
    state MASTER # MASTER on haproxy-nodes-1, BACKUP on haproxy-nodes-2
    interface ens3 # Interface name
    virtual_router_id 255
    priority 101 # 101 on haproxy, 100 on haproxy2
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    unicast_src_ip 10.20.10.101      # IP address of this machine
    unicast_peer {
        10.20.10.102                 # IP address of peer machines
   }
    virtual_ipaddress {
        10.20.10.200
    }
    
    track_script {
        check_haproxy
    }
}
</code></pre><h4 id="haproxy-nodes-2">Haproxy nodes 2</h4>
<pre tabindex="0"><code>global_defs {
   notification_email {
     root@localhost
   }
   notification_email_from root@localhost
   smtp_server localhost
   smtp_connect_timeout 30
}

# Script used to check if HAProxy is running
vrrp_script check_haproxy {
    script &#34;killall -0 haproxy&#34;
    interval 2 
    weight 2
}

vrrp_instance VI_1 {
    state BACKUP # MASTER on haproxy-nodes-1, BACKUP on haproxy-nodes-2
    interface ens3 # Interface name
    virtual_router_id 255
    priority 101 # 101 on haproxy, 100 on haproxy2
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    unicast_src_ip 10.20.10.102      # IP address of this machine
    unicast_peer {
        10.20.10.101                 # IP address of peer machines
   }
    virtual_ipaddress {
        10.20.10.200
    }
    
    track_script {
        check_haproxy
    }
}
</code></pre><h4 id="allow-a-process-to-bind-to-a-non-local-ip-address">Allow a process to bind to a non-local IP address</h4>
<pre tabindex="0"><code>echo &#34;net.ipv4.ip_nonlocal_bind=1&#34; | sudo tee /etc/sysctl.d/ip_nonlocal_bind.conf
sudo sysctl --system
</code></pre><h4 id="restart-keepalived">Restart keepalived</h4>
<pre tabindex="0"><code>sudo systemctl restart keepalived
sudo systemctl status keepalived
sudo systemctl enable keepalived
</code></pre><h4 id="verify-keepalived-ip-address">Verify Keepalived IP Address</h4>
<p>Make sure VRRP IP active only on LB Nodes 1</p>
<p><img src="./keepalived.png" alt="keepalived"></p>
<h3 id="only-master-1-node"><strong>Only Master-1 node</strong></h3>
<hr>
<h4 id="initialize-the-cluster">Initialize the Cluster</h4>
<pre tabindex="0"><code>sudo nano kubeadm-config.yaml
</code></pre><pre tabindex="0"><code>apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: stable
controlPlaneEndpoint: &#34;fi-k8s-vrrp-master:6443&#34;
networking:
    podSubnet: &#34;10.244.0.0/16&#34;    
</code></pre><pre tabindex="0"><code>kubeadm init --config=kubeadm-config.yaml --upload-certs
</code></pre><pre tabindex="0"><code>mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre><h3 id="install-calico-networking-cni">Install Calico Networking (CNI)</h3>
<pre tabindex="0"><code>kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
kubectl get pods -n kube-system
</code></pre><p> </p>
<h3 id="all-master-nodes-except-master-1"><strong>All Master nodes except Master-1</strong></h3>
<hr>
<h4 id="join-master-nodes">Join master nodes</h4>
<pre tabindex="0"><code>kubeadm join fi-k8s-vrrp-master:6443 --token po9o1t.et1h4u50mov73omo \
        --discovery-token-ca-cert-hash sha256:1e0b4eac0402becb5b6ac1a3f1cd52f109f8bfbe32d8a4213a9e37130f67c99b \
        --control-plane --certificate-key fa564b2d3dadaebb8d7690dad2c23a427b2eafd409d0731e67a3ab14050a3872
</code></pre><p> </p>
<h3 id="all-worker-nodes"><strong>All Worker nodes</strong></h3>
<hr>
<h4 id="join-worker-nodes">Join worker nodes</h4>
<pre tabindex="0"><code>kubeadm join fi-k8s-vrrp-master:6443 --token po9o1t.et1h4u50mov73omo \
        --discovery-token-ca-cert-hash sha256:1e0b4eac0402becb5b6ac1a3f1cd52f109f8bfbe32d8a4213a9e37130f67c99b 
</code></pre><p> </p>
<h3 id="verify-all-nodes-already-join"><strong>Verify All nodes already join</strong></h3>
<hr>
<p><code>kubectl get nodes</code></p>
<p><img src="./verify.png" alt="ready"></p>
<h4 id="testing-deploy-pod">Testing deploy POD</h4>
<pre tabindex="0"><code>sudo nano nginx.yaml
</code></pre><pre tabindex="0"><code>apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80
</code></pre><h4 id="running--deploy-pod">Running &amp; deploy POD</h4>
<pre tabindex="0"><code>sudo kubectl apply -f  nginx.yaml    
</code></pre><h4 id="verification">Verification</h4>
<p><img src="./nginx.png" alt="nginx"></p>
<p> </p>
<h4 id="next--install-storage-cluster-rook--ceph-in-kubernetes">Next : Install storage cluster ROOK &amp; CEPH in Kubernetes</h4>
<p> 
 </p>
<h4 id="reference-">Reference :</h4>
<p><a href="https://itnext.io/create-a-highly-available-kubernetes-cluster-using-keepalived-and-haproxy-37769d0a65ba">https://itnext.io/create-a-highly-available-kubernetes-cluster-using-keepalived-and-haproxy-37769d0a65ba</a></p>
]]></content>
        </item>
        
        <item>
            <title>2. Deploy storage cluster ROOK with CEPH in Kubernetes</title>
            <link>/posts/deploy-storage-cluster-rook-with-ceph-in-kubernetes/</link>
            <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
            
            <guid>/posts/deploy-storage-cluster-rook-with-ceph-in-kubernetes/</guid>
            <description>Specification : Kubernetes, ROOK, CEPH
Lab Topology You can check installation kubernetes cluster in previous documentation, https://assyafii.com/docs/install-kubernetes-cluster-multi-master-ha/ Storages nodes disks We use 3 disks extended (vdb, vdc, vdd) in each of storage-nodes, total 6 disks for rook cluster.
Detail disks Master node Clone ROOK Project cd ~ git clone --single-branch --branch release-1.7 https://github.com/rook/rook.git Deploy the Rook Operator cd rook/cluster/examples/kubernetes/ceph kubectl create -f crds.yaml kubectl create -f common.yaml kubectl create -f operator.</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : Kubernetes, ROOK, CEPH</p>
</blockquote>
<h3 id="lab-topology"><strong>Lab Topology</strong></h3>
<p>You can check installation kubernetes cluster in previous documentation, <a href="https://assyafii.com/docs/install-kubernetes-cluster-multi-master-ha/">https://assyafii.com/docs/install-kubernetes-cluster-multi-master-ha/</a>
<img src="./k8s-topology.png" alt="k8s-topology"></p>
<p> </p>
<h3 id="storages-nodes-disks"><strong>Storages nodes disks</strong></h3>
<p>We use 3 disks extended (vdb, vdc, vdd) in each of storage-nodes, total 6 disks for rook cluster.</p>
<h4 id="detail-disks">Detail disks</h4>
<p><img src="./cluster-rook.png" alt="rook-cluster"></p>
<p><img src="./disks.png" alt="rook-disks"></p>
<h3 id="master-node"><strong>Master node</strong></h3>
<hr>
<h4 id="clone-rook-project">Clone ROOK Project</h4>
<pre tabindex="0"><code>cd ~
git clone --single-branch --branch release-1.7 https://github.com/rook/rook.git
</code></pre><h4 id="deploy-the-rook-operator">Deploy the Rook Operator</h4>
<pre tabindex="0"><code>cd rook/cluster/examples/kubernetes/ceph
kubectl create -f crds.yaml
kubectl create -f common.yaml
kubectl create -f operator.yaml
</code></pre><h4 id="make-sure-all-rook-components-already-up">Make sure all Rook components already UP</h4>
<p><img src="./operator.png" alt="rook-operator"></p>
<h4 id="verify-the-rook-ceph-operator-is-in-the-running">Verify the rook-ceph-operator is in the Running</h4>
<p><img src="./pod.png" alt="rook-pod"></p>
<h4 id="create-a-ceph-storage-cluster">Create a Ceph Storage Cluster</h4>
<p>Set default namespace to rook-ceph, you can set to default namespace agaian after installation.</p>
<pre tabindex="0"><code>kubectl config set-context --current --namespace rook-ceph
</code></pre><h5 id="important--expicitly-define-the-nodes-and-raw-disks-devices-to-be-used">Important : Expicitly define the nodes and raw disks devices to be used.</h5>
<p>For any further customizations, check in <a href="https://rook.io/docs/rook/latest/ceph-cluster-crd.html">ROOK Ceph Cluster CRD documentation.</a></p>
<pre tabindex="0"><code>sudo nano cluster.yaml
</code></pre><p><img src="./cluster.png" alt="rook-cluster"></p>
<h4 id="deploy-rook-ceph-cluster">Deploy Rook ceph cluster</h4>
<p><code>kubectl create -f cluster.yaml</code></p>
<p>Need some minutes to deploy it, make sure all completed</p>
<pre tabindex="0"><code>kubectl get -n rook-ceph jobs.batch
kubectl -n rook-ceph get cephcluster
</code></pre><p><img src="./jobs.png" alt="rook-jobs"></p>
<h4 id="deploy-rook-ceph-toolbox">Deploy Rook Ceph toolbox</h4>
<p>The Rook Ceph toolbox is a container with common tools used for rook debugging and testing.</p>
<pre tabindex="0"><code>cd ~
cd rook/cluster/examples/kubernetes/ceph
kubectl  apply  -f toolbox.yaml
kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash
</code></pre><p>My cluster status CEPH Warning, because degraded data, but no problem.
<img src="./ceph.png" alt="rook-ceph"></p>
<p>All OSD UP
<img src="./osd.png" alt="rook-osd"></p>
<h4 id="create-pool-shared-filesystem-in-ceph-cephfs">Create pool shared filesystem in CEPH (cephfs)</h4>
<pre tabindex="0"><code>cd ~
cd rook/cluster/examples/kubernetes/ceph/
sudo nano filesystem.yaml
</code></pre><p>Write your filesystem metadata name.</p>
<p><img src="./cephfs.png" alt="rook-cephfs"></p>
<p>Verify if metadata and data pools are created.
<img src="./verify.png" alt="rook-verify"></p>
<h4 id="create-storage-class-for-cephfs">Create storage class for cephfs</h4>
<pre tabindex="0"><code>sudo nano csi/cephfs/storageclass.yaml
kubectl create -f csi/cephfs/storageclass.yaml
kubectl get sc
</code></pre><p>change fsName &amp; pool name
<img src="./create-sc.png" alt="rook-sc-create"></p>
<p>Verify storage class created
<img src="./sc.png" alt="rook-sc"></p>
<h4 id="last-step-testing-create-pvc--pod">Last step, Testing create PVC &amp; POD</h4>
<pre tabindex="0"><code>kubectl create  -f  csi/cephfs/pvc.yaml
kubectl get pvc
kubectl create -f csi/cephfs/pod.yaml
kubectl get pod
</code></pre><p>Example manifest file PVC</p>
<pre tabindex="0"><code>apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cephfs-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: rook-cephfs
</code></pre><p>Example manifest file POD</p>
<pre tabindex="0"><code>apiVersion: v1
kind: Pod
metadata:
  name: csicephfs-demo-pod
spec:
  containers:
    - name: web-server
      image: nginx
      volumeMounts:
        - name: mypvc
          mountPath: /var/lib/www/html
  volumes:
    - name: mypvc
      persistentVolumeClaim:
        claimName: cephfs-pvc
        readOnly: false
</code></pre><h4 id="verify-pod--pvc-already-created">Verify POD &amp; PVC Already created</h4>
<p>Persistent Volume
<img src="./pvc.png" alt="rook-pvc"></p>
<p>POD with PVC
<img src="./pod-testing.png" alt="rook-pod-testing"></p>
<p> 
 </p>
<h4 id="reference-">Reference :</h4>
<p><a href="https://computingforgeeks.com/how-to-deploy-rook-ceph-storage-on-kubernetes-cluster/">https://computingforgeeks.com/how-to-deploy-rook-ceph-storage-on-kubernetes-cluster/</a></p>
]]></content>
        </item>
        
        <item>
            <title>3. Deploy PortWorx storage in kubernetes</title>
            <link>/posts/deploy-portworx-storage-in-kubernetes/</link>
            <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
            
            <guid>/posts/deploy-portworx-storage-in-kubernetes/</guid>
            <description>Specification : Kubernetes, PortWorx, Storage
PortWorx storage cluster Portworx by Pure Storage is a cloud native storage solution, provides a fully integrated solution for persistent storage, data protection, disaster recovery, data security, cross-cloud and data migrations, and automated capacity management for applications running on Kubernetes. If you see in each of documents, portworx have big IOPS &amp;amp; Bandwidth.
Lab Topology IP Address Nodes 10.20.10.230 sf-k8s-master-1 10.20.10.235 sf-k8s-node-1 10.20.10.241 sf-k8s-portworx-1 10.</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : Kubernetes, PortWorx, Storage</p>
</blockquote>
<h3 id="portworx-storage-cluster"><strong>PortWorx storage cluster</strong></h3>
<p>Portworx by Pure Storage is a cloud native storage solution, provides a fully integrated solution for persistent storage, data protection, disaster recovery, data security, cross-cloud and data migrations, and automated capacity management for applications running on Kubernetes. If you see in each of documents, portworx have big IOPS &amp; Bandwidth.</p>
<p> </p>
<h3 id="lab-topology"><strong>Lab Topology</strong></h3>
<p><img src="./portworx.png" alt="portworx-topology">
 </p>
<table>
<thead>
<tr>
<th style="text-align:center">IP Address</th>
<th style="text-align:center">Nodes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">10.20.10.230</td>
<td style="text-align:center">sf-k8s-master-1</td>
</tr>
<tr>
<td style="text-align:center">10.20.10.235</td>
<td style="text-align:center">sf-k8s-node-1</td>
</tr>
<tr>
<td style="text-align:center">10.20.10.241</td>
<td style="text-align:center">sf-k8s-portworx-1</td>
</tr>
<tr>
<td style="text-align:center">10.20.10.242</td>
<td style="text-align:center">sf-k8s-portworx-2</td>
</tr>
</tbody>
</table>
<h4 id="first-make-your-k8s-cluster-already-running">First, make your k8s cluster already running</h4>
<p>If your cluster ready, you can check in previous docummentation for installation <a href="https://assyafii.com/docs/install-kubernetes-cluster-multi-master-ha/">https://assyafii.com/docs/install-kubernetes-cluster-multi-master-ha/</a></p>
<p><img src="./ready.png" alt="portworx-ready"></p>
<h4 id="add-labels-pxmetadata-nodetrue-for-portworx-nodes">Add labels px/metadata-node=true for portworx nodes</h4>
<pre tabindex="0"><code>kubectl label nodes sf-k8s-portworx-1 sf-k8s-portworx-2 px/metadata-node=true
</code></pre><h4 id="create-portworx-template-generator">Create portworx template generator</h4>
<p><strong>1. Login to <a href="https://central.portworx.com/specGen/wizard">https://central.portworx.com/specGen/wizard</a> &amp; choose version</strong>
<img src="./1.png" alt="portworx-1"></p>
<p><strong>2. Checklist use operator</strong>
<img src="./2.png" alt="portworx-2"></p>
<p><strong>3. You need configure KVDB Devices if production, for testing skip this</strong>
<img src="./3.png" alt="portworx-3"></p>
<p><strong>4. Skip network configuration</strong>
<img src="./4.png" alt="portworx-4"></p>
<p><strong>5. Add cluster name prefix</strong>
<img src="./5.png" alt="portworx-5"></p>
<p><strong>6. Apply deployment to cluster from template created</strong>
<img src="./6.png" alt="portworx-6"></p>
<h4 id="verification">Verification</h4>
<p><strong>Checks status POD portworx running</strong></p>
<pre tabindex="0"><code>kubectl get pods -n kube-system
</code></pre><p><strong>If running all, check cluster portworx</strong></p>
<pre tabindex="0"><code>PX_POD=$(kubectl get pods -l name=portworx -n kube-system -o jsonpath=&#39;{.items[0].metadata.name}&#39;)
kubectl exec -it $PX_POD -n kube-system -- /opt/pwx/bin/pxctl status
</code></pre><p><img src="./7.png" alt="portworx-7"></p>
<h4 id="testing-scenario">Testing scenario</h4>
<p>For test, wee will deploy POD FIO then benchmark on directory which mount to portworx cluster.</p>
<p><img src="./8.png" alt="portworx-8"></p>
<p><strong>Create PVC &amp; POD For testing</strong></p>
<pre tabindex="0"><code>apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: px-pvc-fio
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 20Gi
  storageClassName: px-replicated
---
apiVersion: v1
kind: Pod
metadata:
  name: px-pod-fio
spec:
  containers:
    - name: fio
      image: vineethac/fio_image
      command: [ &#34;/bin/bash&#34;, &#34;-c&#34;, &#34;--&#34; ]
      args: [ &#34;while true; do sleep 30; done;&#34; ]
      imagePullPolicy: IfNotPresent
      volumeMounts:
        - mountPath: &#34;/mnt/px&#34;
          name: px-pvc-fio-vol
  volumes:
    - name: px-pvc-fio-vol
      persistentVolumeClaim:
        claimName: px-pvc-fio
</code></pre><p><img src="./9.png" alt="portworx-9"></p>
<p><strong>FIO Testing in directory /mnt/px</strong></p>
<p><img src="./10.png" alt="portworx-10"></p>
<h4 id="reference-">Reference :</h4>
<p><a href="https://thenewstack.io/tutorial-install-and-configure-portworx-on-a-bare-metal-kubernetes-cluster/">https://thenewstack.io/tutorial-install-and-configure-portworx-on-a-bare-metal-kubernetes-cluster/</a></p>
<p><a href="https://docs.portworx.com/portworx-install-with-kubernetes/on-premise/airgapped/">https://docs.portworx.com/portworx-install-with-kubernetes/on-premise/airgapped/</a></p>
]]></content>
        </item>
        
        <item>
            <title>4. 5G Cloud Native Simulation with Open5Gs</title>
            <link>/posts/5g-cloud-native-simulation-with-open5gs/</link>
            <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
            
            <guid>/posts/5g-cloud-native-simulation-with-open5gs/</guid>
            <description>Specification : Kubernetes, HELM, Istio, Open5Gs, ROOK, CEPH, Rancher
Lab Topology Create Namespaces for practices kubectl create ns open5gs Install Service mesh Istio (optional) curl -L https://istio.io/downloadIstio | sh - cd istio-1.12.1 export PATH=$PWD/bin:$PATH istioctl install --set profile=demo -y Add a namespace label to instruct Istio to automatically inject Envoy sidecar proxies when you deploy your application later:
kubectl label namespace open5gs istio-injection=enabled Install Addons packages
cd ~/istio-1.12.1/samples/addons kubectl apply -f prometheus.</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : Kubernetes, HELM, Istio, Open5Gs, ROOK, CEPH, Rancher</p>
</blockquote>
<h3 id="lab-topology"><strong>Lab Topology</strong></h3>
<p><img src="./5Glab.png" alt="5g-topology"></p>
<h4 id="create-namespaces-for-practices">Create Namespaces for practices</h4>
<pre tabindex="0"><code>kubectl create ns open5gs
</code></pre><h4 id="install-service-mesh-istio-optional">Install Service mesh Istio (optional)</h4>
<pre tabindex="0"><code>curl -L https://istio.io/downloadIstio | sh -
cd istio-1.12.1
export PATH=$PWD/bin:$PATH
istioctl install --set profile=demo -y
</code></pre><p>Add a namespace label to instruct Istio to automatically inject Envoy sidecar proxies when you deploy your application later:</p>
<pre tabindex="0"><code>kubectl label namespace open5gs istio-injection=enabled
</code></pre><p><strong>Install Addons packages</strong></p>
<pre tabindex="0"><code>cd ~/istio-1.12.1/samples/addons
kubectl apply -f prometheus.yaml #for data sources monitoring
kubectl apply -f kiali.yaml #for dashboard visualization istio
kubectl apply -f jaeger.yaml #for tracing log
kubectl apply -f grafana.yaml #for dashboard monitoring (visualization)
</code></pre><h4 id="install-rancher-optional">Install Rancher (optional)</h4>
<pre tabindex="0"><code>helm repo add rancher-latest https://releases.rancher.com/server-charts/latest
kubectl create namespace cattle-system
</code></pre><p><strong>Install crds Cert Manager</strong></p>
<pre tabindex="0"><code>kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.5.1/cert-manager.crds.yaml
</code></pre><p><strong>Add the Jetstack Helm repository</strong></p>
<pre tabindex="0"><code>helm repo add jetstack https://charts.jetstack.io
</code></pre><p><strong>Update your local Helm chart repository cache</strong></p>
<pre tabindex="0"><code>helm repo update
</code></pre><p><strong>Install the cert-manager Helm chart</strong></p>
<pre tabindex="0"><code>helm install cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --create-namespace \
  --version v1.5.1
</code></pre><hr>
<pre tabindex="0"><code>kubectl get pods --namespace cert-manager
</code></pre><h4 id="install-rancher-with-helm">Install Rancher with Helm</h4>
<pre tabindex="0"><code>helm install rancher rancher-latest/rancher \
  --namespace cattle-system \
  --set hostname=rancher.my.org \
  --set replicas=3
</code></pre><p><strong>Wait for Rancher to be rolled out</strong></p>
<pre tabindex="0"><code>kubectl -n cattle-system rollout status deploy/rancher
</code></pre><p><strong>Verify that the Rancher Server is Successfully Deployed</strong></p>
<pre tabindex="0"><code>kubectl -n cattle-system get deploy rancher
</code></pre><p><img src="./rancher.png" alt="rancher"></p>
<h4 id="install-helm">Install HELM</h4>
<p>We use HELM for automatic deployment in kubernetes.</p>
<pre tabindex="0"><code>curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
chmod 700 get_helm.sh
./get_helm.sh
helm version    
</code></pre><h4 id="clone-repo-for-simulation">Clone repo for simulation</h4>
<pre tabindex="0"><code>cd ~
git clone https://bitbucket.org/infinitydon/opensource-5g-core-service-mesh.git
git clone https://github.com/Gradiant/openverso-charts.git
</code></pre><h4 id="configure-amf-services-optional">Configure AMF Services (optional)</h4>
<p>This services if you want use NodePort &amp; can access from external cluster.</p>
<pre tabindex="0"><code>cd ~/opensource-5g-core-service-mesh/helm-chart
sudo nano templates/amf-deploy.yaml
</code></pre><p>Uncomment in AMF service amf-open5gs-sctp
<img src="./amf-deploy.png" alt="amf-deploy"></p>
<h4 id="changed-sd-to-ffffff-in-amf-configmap">Changed sd to ffffff in amf-configmap</h4>
<pre tabindex="0"><code>nano templates/amf-configmap.yaml
</code></pre><p><img src="./amf-configmap.png" alt="amf-configmap"></p>
<h4 id="change-mongodb-configuration">Change mongodb configuration</h4>
<p>We will use <strong>ROOK Ceph</strong> for persistent volume, need <strong>comment existing persistent volume &amp; add StorageClassName in persistent volume claim</strong>.</p>
<pre tabindex="0"><code>nano templates/mongodb.yaml
</code></pre><p><img src="./mongodb.png" alt="mongodb"></p>
<h4 id="deploy-open5gs-with-helm-chart">Deploy open5gs with helm-chart</h4>
<pre tabindex="0"><code>cd ~/opensource-5g-core-service-mesh/helm-chart
helm -n open5gs install -f values.yaml open ./
</code></pre><h4 id="make-sure-all-pod--services-already-running">Make sure all POD &amp; Services already running</h4>
<p><img src="./running.png" alt="running"></p>
<h4 id="register-ue-user-equipment-in-open5gs-dashboard">Register UE (User Equipment in Open5Gs dashboard)</h4>
<p>Open dashboard use IP webui services <code>10.101.169.188</code></p>
<pre tabindex="0"><code>Username : admin
Password : 1423
</code></pre><p><img src="./login.png" alt="login"></p>
<p>Register User Equipment (UE) with detail bellow :</p>
<pre tabindex="0"><code>IMSI : 208930000000001
Key : 465B5CE8B199B49FAA5F0A2EE238A6BC
OP : E8ED289DEBA952E4283B54E88E6183CA
opType: OPC
apn: internet
sst: 1
sd: &#34;ffffff&#34;
</code></pre><p><img src="./register.png" alt="register"></p>
<h3 id="configure-ueransim-ue--gnb"><strong>Configure UERANSIM (UE &amp; gNB)</strong></h3>
<hr>
<h4 id="install-ueransim-helm-depedency">Install UERANSIM Helm depedency</h4>
<pre tabindex="0"><code>cd ~
cd ~/openverso-charts/charts/ueransim
helm dep update ./
</code></pre><h4 id="change-value-in-ue">Change value in UE</h4>
<pre tabindex="0"><code>sudo nano values.yaml
</code></pre><pre tabindex="0"><code>mcc: &#39;208&#39;
mnc: &#39;93&#39;
tac: &#39;7&#39;
</code></pre><h4 id="change-amf-address-in-gnb">Change AMF Address in gNB</h4>
<p>You must change address to AMF POD address, check with &lsquo;kubectl get pod -o wide -n open5gs | grep amf&rsquo;</p>
<p><img src="./amf-address.png" alt="amf-address"></p>
<pre tabindex="0"><code>sudo nano resources/gnb.yaml
</code></pre><p><img src="./gnb.png" alt="gnb"></p>
<h4 id="running-ueransim">Running UERANSIM</h4>
<pre tabindex="0"><code>helm -n open5gs install -f values.yaml ueransim ./
kubectl get pod -n open5gs | grep ueransim
</code></pre><h4 id="verify-logs-ue-connected-to-gnb--amf">Verify Logs UE Connected to gNB &amp; AMF</h4>
<p><strong>AMF Logs</strong>
<img src="./amf-log.png" alt="amf-log"></p>
<p><strong>gNB Logs</strong>
<img src="./gnb-log.png" alt="gnb-log"></p>
<p><strong>UE Logs</strong>
<img src="./ue-log.png" alt="ue-log"></p>
<h4 id="verify-ping-to-internet-via-rancher-dashboard">Verify ping to Internet via Rancher dashboard</h4>
<p><strong>UE Container</strong></p>
<p>Note : Bellow not show reply, because in TAP Interface (debian) not showing reply, we can see tcpdump in UPF POD.</p>
<pre tabindex="0"><code>ping 8.8.8.8 -I uesimtun0
</code></pre><p><img src="./ping-ue.png" alt="ue-ping"></p>
<p><strong>UPF POD</strong></p>
<p>We can see ICMP request reply, from UE IP Address &amp; Google IP.</p>
<pre tabindex="0"><code>sudo apt install tcpdump
tcpdump -i ogstun
</code></pre><p><img src="./ping-upf.png" alt="upf-ping"></p>
<h4 id="grafana-dashboard">Grafana Dashboard</h4>
<p><img src="./grafana.png" alt="grafana"></p>
<h4 id="istio-kiali-dashboard">Istio Kiali Dashboard</h4>
<p><img src="./kiali.png" alt="kiali"></p>
<p> 
 </p>
<h4 id="reference-">Reference :</h4>
<p><a href="https://medium.com/rahasak/5g-core-network-setup-with-open5gs-and-ueransim-cd0e77025fd7">https://medium.com/rahasak/5g-core-network-setup-with-open5gs-and-ueransim-cd0e77025fd7</a></p>
<p><a href="https://levelup.gitconnected.com/opensource-5g-core-with-service-mesh-bba4ded044fa">https://levelup.gitconnected.com/opensource-5g-core-with-service-mesh-bba4ded044fa</a></p>
<p><a href="https://github.com/Gradiant/openverso-charts.git">https://github.com/Gradiant/openverso-charts.git</a></p>
]]></content>
        </item>
        
        <item>
            <title>5. Deploy CRUD using AWS API Gateway, Serverless Lambda and DynamoDB</title>
            <link>/posts/deploy-crud-using-aws-api-gateway-serverless-lambda-and-dynamodb/</link>
            <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
            
            <guid>/posts/deploy-crud-using-aws-api-gateway-serverless-lambda-and-dynamodb/</guid>
            <description>Specification : AWS, API Gateway, Serverless, Lambda, RDS, Postman
Lab Topology Step-by-step Create IAM role for allow configuration Create Database table with DynamoDB Create AWS API Gateway service Create Lambda function Testing CRUD with postman Verify A. Create IAM role First step is create IAM role to allow Lambda function to call AWS services, for it you can follow guide bellow :
Login to your AWS console, search and chose IAM menu Choose Roles and create role Choose AWS Services -&amp;gt; Lambda and Next And you can see menu bellow For integrate lambda with RDS &amp;amp; cloudwatch, wee need filter &amp;amp; checklist cloudwatchfullaccess And the last one, search dynamodb and checklist full access permissions Add rolename Verify you already added two roles for it, and create role B.</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : AWS, API Gateway, Serverless, Lambda, RDS, Postman</p>
</blockquote>
<h3 id="lab-topology"><strong>Lab Topology</strong></h3>
<p><img src="./aws-lambda-diagram.png" alt="aws-lambda-diagram"></p>
<p><img src="./aws-lambda-detail.png" alt="aws-lambda-detail"></p>
<p> </p>
<h4 id="step-by-step">Step-by-step</h4>
<ul>
<li>Create IAM role for allow configuration</li>
<li>Create Database table with DynamoDB</li>
<li>Create AWS API Gateway service</li>
<li>Create Lambda function</li>
<li>Testing CRUD with postman</li>
<li>Verify</li>
</ul>
<h4 id="a-create-iam-role">A. Create IAM role</h4>
<p>First step is create IAM role to allow Lambda function to call AWS services, for it you can follow guide bellow :</p>
<ol>
<li>Login to your AWS console, search and chose IAM menu</li>
</ol>
<p><img src="./docs/aws1.png" alt="aws1"></p>
<ol start="2">
<li>Choose <code>Roles</code> and create <code>role</code></li>
</ol>
<p><img src="./docs/aws2.png" alt="aws2"></p>
<ol start="3">
<li>Choose AWS Services -&gt; Lambda and Next</li>
</ol>
<p><img src="./docs/aws3.png" alt="aws3"></p>
<ol start="4">
<li>
<p>And you can see menu bellow
<img src="./docs/aws4.png" alt="aws4"></p>
</li>
<li>
<p>For integrate lambda with RDS &amp; cloudwatch, wee need filter &amp; checklist <code>cloudwatchfullaccess</code>
<img src="./docs/aws5.png" alt="aws5"></p>
</li>
<li>
<p>And the last one, search <code>dynamodb</code> and checklist full access permissions
<img src="./docs/aws6.png" alt="aws6"></p>
</li>
<li>
<p>Add rolename
<img src="./docs/aws7.png" alt="aws7"></p>
</li>
<li>
<p>Verify you already added two roles for it, and create role
<img src="./docs/aws8.png" alt="aws8"></p>
</li>
</ol>
<hr>
<p> </p>
<h4 id="b-create-rds-dynamodb-table">B. Create RDS DynamoDB Table</h4>
<p>Next step we need create database for store data, with step bellow :</p>
<ol>
<li>Choose DynamoDB services</li>
</ol>
<p><img src="./docs/aws9.png" alt="aws9"></p>
<ol start="2">
<li>Choose Dashboard and create <code>Table</code></li>
</ol>
<p><img src="./docs/aws10.png" alt="aws10"></p>
<ol start="3">
<li>Put table name, you can same with our tutorial use <code>food-aws-serverless</code> and put <code>Partition Key</code> with <code>foodId</code> for indexing like bellow, and create table</li>
</ol>
<p><img src="./docs/aws11.png" alt="aws11"></p>
<ol start="4">
<li>You can see table after created</li>
</ol>
<p><img src="./docs/aws12.png" alt="aws12"></p>
<hr>
<p> </p>
<h4 id="c-create-lambda-function">C. Create Lambda Function</h4>
<ol>
<li>After create RDS, next create Lambda function to integrate between API Gateway to RDS DynamoDB</li>
</ol>
<p><img src="./docs/aws13.png" alt="aws13"></p>
<ol start="2">
<li>Choose <code>Functions</code> and <code>create function</code></li>
</ol>
<p><img src="./docs/aws14.png" alt="aws14"></p>
<ol start="3">
<li>And follow function like bellow and create function</li>
</ol>
<p><img src="./docs/aws15.png" alt="aws15"></p>
<p><img src="./docs/aws16.png" alt="aws16"></p>
<ol start="4">
<li>And you can see lambda function has been created, after that we need increase specs of lambda with step bellow. Click <code>configuration &gt; Edit</code>, Increase value of Memory and Storage and save.</li>
</ol>
<p><img src="./docs/aws17.png" alt="aws17">
<img src="./docs/aws18.png" alt="aws18"></p>
<ol start="5">
<li>And <code>Important</code> step is create <code>lambda function</code> for CRUD, choose code &gt; edit lambda_function.py &gt; copas code from bellow &gt; and last deploy</li>
</ol>
<p><img src="./docs/aws19.png" alt="aws19"></p>
<p><code>lambda_function.py</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> boto3
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> botocore.vendored <span style="color:#f92672">import</span> requests
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> custom_encoder <span style="color:#f92672">import</span> CustomEncoder
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> logging
</span></span><span style="display:flex;"><span>logger <span style="color:#f92672">=</span> logging<span style="color:#f92672">.</span>getLogger()
</span></span><span style="display:flex;"><span>logger<span style="color:#f92672">.</span>setLevel(logging<span style="color:#f92672">.</span>INFO)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dynamodbTableName <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;food-aws-serverless&#39;</span>
</span></span><span style="display:flex;"><span>dynamodb <span style="color:#f92672">=</span> boto3<span style="color:#f92672">.</span>resource(<span style="color:#e6db74">&#39;dynamodb&#39;</span>)
</span></span><span style="display:flex;"><span>table <span style="color:#f92672">=</span> dynamodb<span style="color:#f92672">.</span>Table(dynamodbTableName)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>getMethod <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;GET&#39;</span>
</span></span><span style="display:flex;"><span>postMethod <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;POST&#39;</span>
</span></span><span style="display:flex;"><span>patchMethod <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;PATCH&#39;</span>
</span></span><span style="display:flex;"><span>deleteMethod <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;DELETE&#39;</span>
</span></span><span style="display:flex;"><span>healthPath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/health&#39;</span>
</span></span><span style="display:flex;"><span>foodPath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/food&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">lambda_handler</span>(event, context):
</span></span><span style="display:flex;"><span>    logger<span style="color:#f92672">.</span>info(event)
</span></span><span style="display:flex;"><span>    httpMethod <span style="color:#f92672">=</span> event[<span style="color:#e6db74">&#39;httpMethod&#39;</span>]
</span></span><span style="display:flex;"><span>    path <span style="color:#f92672">=</span> event[<span style="color:#e6db74">&#39;path&#39;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> httpMethod <span style="color:#f92672">==</span> getMethod <span style="color:#f92672">and</span> path <span style="color:#f92672">==</span> healthPath:
</span></span><span style="display:flex;"><span>        response <span style="color:#f92672">=</span> buildResponse(<span style="color:#ae81ff">200</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> httpMethod <span style="color:#f92672">==</span> getMethod <span style="color:#f92672">and</span> path <span style="color:#f92672">==</span> foodPath:
</span></span><span style="display:flex;"><span>        response <span style="color:#f92672">=</span> getFood(event[<span style="color:#e6db74">&#39;queryStringParameters&#39;</span>][<span style="color:#e6db74">&#39;foodId&#39;</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> httpMethod <span style="color:#f92672">==</span> postMethod <span style="color:#f92672">and</span> path <span style="color:#f92672">==</span> foodPath:
</span></span><span style="display:flex;"><span>        response <span style="color:#f92672">=</span> saveFood(json<span style="color:#f92672">.</span>loads(event[<span style="color:#e6db74">&#39;body&#39;</span>]))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> httpMethod <span style="color:#f92672">==</span> patchMethod <span style="color:#f92672">and</span> path <span style="color:#f92672">==</span> foodPath:
</span></span><span style="display:flex;"><span>        requestBody <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>loads(event[<span style="color:#e6db74">&#39;body&#39;</span>])
</span></span><span style="display:flex;"><span>        response <span style="color:#f92672">=</span> modifyFood(requestBody[<span style="color:#e6db74">&#39;foodId&#39;</span>], requestBody[<span style="color:#e6db74">&#39;updateKey&#39;</span>], requestBody[<span style="color:#e6db74">&#39;updateValue&#39;</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> httpMethod <span style="color:#f92672">==</span> deleteMethod <span style="color:#f92672">and</span> path <span style="color:#f92672">==</span> foodPath:
</span></span><span style="display:flex;"><span>        requestBody <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>loads(event[<span style="color:#e6db74">&#39;body&#39;</span>])
</span></span><span style="display:flex;"><span>        response <span style="color:#f92672">=</span> deleteFood(requestBody[<span style="color:#e6db74">&#39;foodId&#39;</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        response <span style="color:#f92672">=</span> buildResponse(<span style="color:#ae81ff">404</span>, <span style="color:#e6db74">&#39;Sorry, Not Found&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> response
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">getFood</span>(foodId):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        response <span style="color:#f92672">=</span> table<span style="color:#f92672">.</span>get_item(
</span></span><span style="display:flex;"><span>            Key<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;foodId&#39;</span>: foodId
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#39;Item&#39;</span> <span style="color:#f92672">in</span> response:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> buildResponse(<span style="color:#ae81ff">200</span>, response[<span style="color:#e6db74">&#39;Item&#39;</span>])
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> buildResponse(<span style="color:#ae81ff">404</span>, {<span style="color:#e6db74">&#39;Message&#39;</span> : <span style="color:#e6db74">&#39;FoodId: </span><span style="color:#e6db74">%s</span><span style="color:#e6db74"> not found&#39;</span> <span style="color:#f92672">%</span> foodId})
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span>:
</span></span><span style="display:flex;"><span>        logger<span style="color:#f92672">.</span>exception(<span style="color:#e6db74">&#39;Do your custom error handling here, I am just gonna log it out there!&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">saveFood</span>(requestBody):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        table<span style="color:#f92672">.</span>put_item(Item<span style="color:#f92672">=</span>requestBody)
</span></span><span style="display:flex;"><span>        body <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;Operation&#39;</span> : <span style="color:#e6db74">&#39;SAVE&#39;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;Message&#39;</span> : <span style="color:#e6db74">&#39;SUCCESS&#39;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;Item&#39;</span> : requestBody
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> buildResponse(<span style="color:#ae81ff">200</span>, body)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span>:
</span></span><span style="display:flex;"><span>        logger<span style="color:#f92672">.</span>exception(<span style="color:#e6db74">&#39;Do your custom error handling here, I am just gonna log it out there!&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">modifyFood</span>(foodId, updateKey, updateValue):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        response <span style="color:#f92672">=</span> table<span style="color:#f92672">.</span>update_item(
</span></span><span style="display:flex;"><span>            Key<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;foodId&#39;</span>: foodId
</span></span><span style="display:flex;"><span>            },
</span></span><span style="display:flex;"><span>            UpdateExpression<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;set </span><span style="color:#e6db74">%s</span><span style="color:#e6db74"> = :value&#39;</span> <span style="color:#f92672">%</span> updateKey,
</span></span><span style="display:flex;"><span>            ExpressionAttributeValues<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;:value&#39;</span>: updateValue
</span></span><span style="display:flex;"><span>            },
</span></span><span style="display:flex;"><span>            ReturnValues<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;UPDATED_NEW&#39;</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        body <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;Operation&#39;</span>: <span style="color:#e6db74">&#39;UPDATE&#39;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;Message&#39;</span>: <span style="color:#e6db74">&#39;SUCCESS&#39;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;UpdatedAttrebutes&#39;</span>: response
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> buildResponse(<span style="color:#ae81ff">200</span>, body)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span>:
</span></span><span style="display:flex;"><span>        logger<span style="color:#f92672">.</span>exception(<span style="color:#e6db74">&#39;Do your custom error handling here, I am just gonna log it out there!&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">deleteFood</span>(foodId):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        response <span style="color:#f92672">=</span> table<span style="color:#f92672">.</span>delete_item(
</span></span><span style="display:flex;"><span>            Key<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;foodId&#39;</span>: foodId
</span></span><span style="display:flex;"><span>            },
</span></span><span style="display:flex;"><span>            ReturnValues<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ALL_OLD&#39;</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        body <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;Operation&#39;</span>: <span style="color:#e6db74">&#39;DELETE&#39;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;Message&#39;</span>: <span style="color:#e6db74">&#39;SUCCESS&#39;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;UpdatedAttrebutes&#39;</span>: response
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> buildResponse(<span style="color:#ae81ff">200</span>, body)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span>:
</span></span><span style="display:flex;"><span>        logger<span style="color:#f92672">.</span>exception(<span style="color:#e6db74">&#39;Do your custom error handling here, I am just gonna log it out there!&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">buildResponse</span>(statusCode, body<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;statusCode&#39;</span> : statusCode,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;headers&#39;</span> : {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;Content-Type&#39;</span>: <span style="color:#e6db74">&#39;application/json&#39;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;Access-Controll-Allow-Origin&#39;</span>: <span style="color:#e6db74">&#39;*&#39;</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> body <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>        response[<span style="color:#e6db74">&#39;body&#39;</span>] <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>dumps(body, cls<span style="color:#f92672">=</span>CustomEncoder)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> response
</span></span></code></pre></div><ol start="6">
<li>And last on is create new file named <code>custom_encoder.py</code> &gt; put code bellow &gt; and <code>deploy</code> again.</li>
</ol>
<p><img src="./docs/aws20.png" alt="aws20"></p>
<p><code>custom_encoder.py</code></p>
<pre tabindex="0"><code>import json
from decimal import Decimal

class CustomEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, Decimal):
            return float(obj)

        return json.JSONEncoder.default(self, obj)
</code></pre><p> </p>
<hr>
<p> </p>
<h4 id="d-create-aws-api-gateway">D. Create AWS API Gateway</h4>
<p>Next is create Rest API gateway, to interact between and user &amp; AWS services, for more you can follow bellow step :</p>
<ol>
<li>Choose <code>AWS API Gateway</code> menu</li>
</ol>
<p><img src="./docs/aws21.png" alt="aws21"></p>
<ol start="2">
<li>Choose <code>Public REST API</code> and <code>build</code></li>
</ol>
<p><img src="./docs/aws22.png" alt="aws22"></p>
<ol start="3">
<li>Click REST &gt; New API and put API name</li>
</ol>
<p><img src="./docs/aws23.png" alt="aws23"></p>
<ol start="4">
<li>And next <code>create Resource</code> for place are API Method, bellow for detail structure :</li>
</ol>
<pre tabindex="0"><code>1. Resource /health
Method GET

2. Resource /food
Method GET, POST, PATCH, DELETE

3. Resource /foods (optional, not important)
Method GET, POST, PATCH, DELETE
</code></pre><p><img src="./docs/aws24.png" alt="aws24"></p>
<ol start="4">
<li>Input <code>Resource name</code>, <code>Resource path</code> and checklist Enable API Gateway</li>
</ol>
<p><img src="./docs/aws25.png" alt="aws25"></p>
<ol start="5">
<li>And create also for /food resource like above</li>
</ol>
<p><img src="./docs/aws27.png" alt="aws27"></p>
<ol start="6">
<li>After create <code>Resource</code>, next create <code>Method</code> for every resource. Click Resource name, for example <code>/health</code> &gt; Create Method</li>
</ol>
<pre tabindex="0"><code>1. Resource /health
Method GET

2. Resource /food
Method GET, POST, PATCH, DELETE

3. Resource /foods (optional, not important)
Method GET, POST, PATCH, DELETE
</code></pre><p><img src="./docs/aws29.png" alt="aws29"></p>
<ol start="7">
<li>Chose Method, for example <code>GET</code> and click OK</li>
</ol>
<p><img src="./docs/aws30.png" alt="aws30"></p>
<ol start="8">
<li>Checklist <code>Lambda Function</code> &gt; Proxy integration &gt; and chose <code>Lambda Function</code> previously created &gt; save</li>
</ol>
<p><img src="./docs/aws31.png" alt="aws31"></p>
<ol start="9">
<li>Click OK for continue, and REPEAT create Method for <code>every resource</code> like it and follow structure</li>
</ol>
<p><img src="./docs/aws32.png" alt="aws32"></p>
<ol start="10">
<li>After all <code>Method and Resource</code> has been created, last step is <code>Deploy API</code> like bellow</li>
</ol>
<p><img src="./docs/aws33.png" alt="aws33"></p>
<ol start="11">
<li>Create new stage name, for example: <code>prod</code>, and finish you already created API Gateway</li>
</ol>
<p><img src="./docs/aws34.png" alt="aws34"></p>
<hr>
<p> </p>
<h4 id="e-testing--verify-crud">E. Testing &amp; Verify CRUD</h4>
<ol>
<li>Before testing, you need download <code>Postman Application</code> for testing API, download on : <a href="https://www.postman.com/downloads/">https://www.postman.com/downloads/</a></li>
<li>First step is copy API Endpoint in APIs menu to access from public internet</li>
</ol>
<p><img src="./docs/aws36.png" alt="aws36"></p>
<h5 id="get-option-health-check">GET Option (Health Check)</h5>
<p>To check API status reached or not, with status 200 OK</p>
<p><img src="./docs/aws37.png" alt="aws37"></p>
<h5 id="post-option">POST Option</h5>
<p>To Put new database to RDS via Json format file (key-value), bellow example to add data :</p>
<pre tabindex="0"><code>{
    &#34;foodId&#34;: &#34;001&#34;,
    &#34;name&#34;: &#34;Banana&#34;,
    &#34;price&#34;: &#34;500&#34;
}
</code></pre><p><img src="./docs/aws38.png" alt="aws38">
<img src="./docs/aws39.png" alt="aws39"></p>
<p>And you can see result success POST in DynamoDB table menu :</p>
<p><img src="./docs/aws40.png" alt="aws40"></p>
<h5 id="delete-option">DELETE Option</h5>
<p>For delete database on RDS you can use delete option with index ID (foodId) like bellow</p>
<p><img src="./docs/aws41.png" alt="aws41"></p>
<p>And you can see after deleted foodId = 002 on RDS Table</p>
<p><img src="./docs/aws42.png" alt="aws42"></p>
<h5 id="get-option">GET Option</h5>
<p>To check detail table by foodId</p>
<p><img src="./docs/aws43.png" alt="aws43"></p>
<h5 id="patch-option">PATCH Option</h5>
<p>Patch you can use for update about value/key, bellow example for update banana price, from 500 to 99999</p>
<p><img src="./docs/aws44.png" alt="aws44">
<img src="./docs/aws45.png" alt="aws45"></p>
<hr>
<p> </p>
<h4 id="reference">Reference</h4>
<ul>
<li>Felix Yu Channel : <a href="https://www.youtube.com/watch?v=9eHh946qTIk&amp;list=LL&amp;index=32&amp;t=159s">https://www.youtube.com/watch?v=9eHh946qTIk&amp;list=LL&amp;index=32&amp;t=159s</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>6. Install OpenStack AIO with Kolla-Ansible in Ubuntu</title>
            <link>/posts/install-openstack-aio-with-kolla-ansible-in-ubuntu/</link>
            <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
            
            <guid>/posts/install-openstack-aio-with-kolla-ansible-in-ubuntu/</guid>
            <description>Specification : OpenStack Yoga, Kolla-ansible, Ubuntu, All-in-one
Lab Topology Specs Value OS Ubuntu 20.04 vCPU 4 RAM 8GB Storage 1 /dev/vda 40 GB Storage 2 /dev/vdb 40 GB Before start Makesure your environment already here :
Installation Update Environment sudo apt update Create VG for cinder-backend (volume instances) pvcreate /dev/vdb vgcreate cinder-volumes /dev/vdb vgs Install depedencies sudo apt install python3-dev libffi-dev gcc libssl-dev python3-venv Create virtual environment (venv) for openstack installation python3 -m venv openstack-yoga source openstack-yoga/bin/activate Install Pip &amp;amp; Ansible For openstack yoga version, you need install ansible version like bellow</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : OpenStack Yoga, Kolla-ansible, Ubuntu, All-in-one</p>
</blockquote>
<p> </p>
<h2 id="lab-topology"><strong>Lab Topology</strong></h2>
<p><img src="./images/aio-yoga.png" alt="aio-yoga"></p>
<p> </p>
<table>
<thead>
<tr>
<th style="text-align:center">Specs</th>
<th style="text-align:center">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">OS</td>
<td style="text-align:center">Ubuntu 20.04</td>
</tr>
<tr>
<td style="text-align:center">vCPU</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">RAM</td>
<td style="text-align:center">8GB</td>
</tr>
<tr>
<td style="text-align:center">Storage 1</td>
<td style="text-align:center">/dev/vda 40 GB</td>
</tr>
<tr>
<td style="text-align:center">Storage 2</td>
<td style="text-align:center">/dev/vdb 40 GB</td>
</tr>
</tbody>
</table>
<hr>
<p> </p>
<h2 id="before-start"><strong>Before start</strong></h2>
<p>Makesure your environment already here :</p>
<p><img src="./images/1.png" alt="openstack-aio"></p>
<h2 id="installation"><strong>Installation</strong></h2>
<h3 id="update-environment">Update Environment</h3>
<pre tabindex="0"><code>sudo apt update
</code></pre><h3 id="create-vg-for-cinder-backend-volume-instances">Create VG for cinder-backend (volume instances)</h3>
<pre tabindex="0"><code>pvcreate /dev/vdb
vgcreate cinder-volumes /dev/vdb
vgs
</code></pre><p><img src="./images/2.png" alt="openstack-aio"></p>
<h3 id="install-depedencies">Install depedencies</h3>
<pre tabindex="0"><code>sudo apt install python3-dev libffi-dev gcc libssl-dev python3-venv
</code></pre><h3 id="create-virtual-environment-venv-for-openstack-installation">Create virtual environment (venv) for openstack installation</h3>
<pre tabindex="0"><code>python3 -m venv openstack-yoga
source openstack-yoga/bin/activate
</code></pre><p><img src="./images/3.png" alt="openstack-aio"></p>
<h3 id="install-pip--ansible">Install Pip &amp; Ansible</h3>
<p>For openstack yoga version, you need install ansible version like bellow</p>
<pre tabindex="0"><code>pip install -U pip
pip install docker
pip install &#39;ansible&gt;=4,&lt;6&#39;
</code></pre><p><img src="./images/4.png" alt="openstack-aio"></p>
<h3 id="install-kolla">Install Kolla</h3>
<pre tabindex="0"><code>pip install kolla-ansible==14.2.0
</code></pre><h3 id="create-kolla-directory-and-copy-file-needed">Create kolla directory and copy file needed</h3>
<pre tabindex="0"><code>mkdir /etc/kolla
cp -r openstack-yoga/share/kolla-ansible/etc_examples/kolla/* /etc/kolla
cp openstack-yoga/share/kolla-ansible/ansible/inventory/* .
mv /etc/kolla/globals.yml /etc/kolla/globals.yml.bak
</code></pre><p><img src="./images/5.png" alt="openstack-aio"></p>
<h3 id="configure-global-configuration">Configure global configuration</h3>
<p>You can configure base on you needed, but for minimal and in this scenario like bellow :</p>
<pre tabindex="0"><code>nano etc/kolla/globals.yml
</code></pre><p><img src="./images/6.png" alt="openstack-aio"></p>
<p>Follow bellow guide :</p>
<pre tabindex="0"><code>kolla_base_distro: &#34;ubuntu&#34;
kolla_install_type: &#34;source&#34;
openstack_release: &#34;yoga&#34;

kolla_internal_vip_address: &#34;172.168.12.100&#34;
network_interface: &#34;ens3&#34;
neutron_external_interface: &#34;ens4&#34;
neutron_plugin_agent: &#34;openvswitch&#34;
api_interface: &#34;ens3&#34;
enable_keystone: &#34;yes&#34;
enable_neutron_trunk: &#34;yes&#34;

enable_cinder: &#34;yes&#34;
enable_cinder_backup: &#34;no&#34;
enable_cinder_backend_lvm: &#34;yes&#34;
enable_horizon: &#34;yes&#34;
enable_neutron_provider_networks: &#34;yes&#34;
</code></pre><h3 id="prepare--setup-ansible">Prepare &amp; setup ansible</h3>
<pre tabindex="0"><code>mkdir /etc/ansible
nano /etc/ansible/ansible.cfg
</code></pre><p>add value like bellow :</p>
<pre tabindex="0"><code>[defaults]
host_key_checking=False
pipelining=True
forks=100
</code></pre><h3 id="generate-kolla-password">Generate Kolla-Password</h3>
<pre tabindex="0"><code>kolla-genpwd
</code></pre><h3 id="openstack-yoga-installation">OpenStack yoga installation</h3>
<pre tabindex="0"><code>ansible -i all-in-one all -m ping
kolla-ansible install-deps
</code></pre><p>If you have <strong>error installation</strong> like bellow you just need install packages, then continue again :</p>
<pre tabindex="0"><code>apt install --reinstall ca-certificates
</code></pre><p><img src="./images/7-issue.png" alt="openstack-aio"></p>
<p><img src="./images/8.png" alt="openstack-aio"></p>
<h3 id="next-bootstrap--deploy-openstack">Next, bootstrap &amp; deploy openstack</h3>
<p>Makesure all deployment not have issue :</p>
<pre tabindex="0"><code>kolla-ansible -i all-in-one bootstrap-servers
kolla-ansible -i all-in-one prechecks
kolla-ansible -i all-in-one deploy
kolla-ansible -i all-in-one post-deploy 
</code></pre><p><img src="./images/9.png" alt="openstack-aio"></p>
<h3 id="verify">Verify</h3>
<p>Verify all container up</p>
<pre tabindex="0"><code>docker ps 
</code></pre><p><img src="./images/10.png" alt="openstack-aio"></p>
<h3 id="get-openstack-horizon-password">Get openstack horizon password</h3>
<pre tabindex="0"><code>cd /etc/kolla
grep keystone admin password /etc/kolla/passwords.yml
</code></pre><p><img src="./images/13.png" alt="openstack-aio"></p>
<h3 id="open-dashboard">Open Dashboard</h3>
<p>Input VIP address, and paste your password from previous :</p>
<p><img src="./images/12.png" alt="openstack-aio"></p>
<p><img src="./images/14.png" alt="openstack-aio"></p>
<h3 id="install-openstack-client-to-manages-with-cli">Install openstack-client to manages with CLI</h3>
<pre tabindex="0"><code>pip install python-openstackclient
</code></pre><p><img src="./images/11.png" alt="openstack-aio"></p>
<h3 id="use-openstack-cli">Use openstack CLI</h3>
<pre tabindex="0"><code>cd /etc/kolla
source admin-openrc.sh
openstack server list 
</code></pre><p> </p>
<h3 id="next-creating-instances"><strong>Next, Creating Instances</strong></h3>
<p>For create instances, you can check next post</p>
<p> 
 </p>
<h3 id="reference-">Reference :</h3>
<p><a href="https://docs.openstack.org/project-deploy-guide/kolla-ansible/yoga/quickstart.html">https://docs.openstack.org/project-deploy-guide/kolla-ansible/yoga/quickstart.html</a></p>
]]></content>
        </item>
        
        <item>
            <title>7. Openstack usages (create network, image, instaces, etc.)</title>
            <link>/posts/openstack-usages-create-network-image-instaces-etc./</link>
            <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
            
            <guid>/posts/openstack-usages-create-network-image-instaces-etc./</guid>
            <description>Specification : openstack, internal &amp;amp; external networks, flavor, images, instances, key, security groups
Summary step Create external network Create router Create internal network Add internal network to router Create images Create flavor Create Instances &amp;amp; key Add floating IP Create security groups Add SG to instances Verify VM connectivity Step 1 by 1 1. Create external network Goto admin pages, and please follow guide correctly
Make Physical Network use physnet1</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : openstack, internal &amp; external networks, flavor, images, instances, key, security groups</p>
</blockquote>
<h3 id="summary-step"><strong>Summary step</strong></h3>
<ol>
<li>Create external network</li>
<li>Create router</li>
<li>Create internal network</li>
<li>Add internal network to router</li>
<li>Create images</li>
<li>Create flavor</li>
<li>Create Instances &amp; key</li>
<li>Add floating IP</li>
<li>Create security groups</li>
<li>Add SG to instances</li>
<li>Verify VM connectivity</li>
</ol>
<p> </p>
<hr>
<p> 
 </p>
<h3 id="step-1-by-1"><strong>Step 1 by 1</strong></h3>
<h4 id="1-create-external-network">1. Create external network</h4>
<p>Goto admin pages, and please follow guide correctly</p>
<p><img src="./images/1.png" alt="aio-yoga"></p>
<p>Make <strong>Physical Network</strong> use <strong>physnet1</strong></p>
<p><img src="./images/2.png" alt="aio-yoga"></p>
<p>Add <strong>Network address</strong> by using <strong>ens4</strong> network address, because for external &amp; floating IP, make sure this network can connect to internet.</p>
<p><img src="./images/3.png" alt="aio-yoga"></p>
<h4 id="2-create-router">2. Create router</h4>
<p>Add router</p>
<p><img src="./images/4.png" alt="aio-yoga"></p>
<p>Make sure <strong>external network</strong> using previously created</p>
<p><img src="./images/5.png" alt="aio-yoga"></p>
<h4 id="3-create-internal-network">3. Create Internal network</h4>
<p>This network for instances private IP, you can use custom address</p>
<p><img src="./images/6.png" alt="aio-yoga">
<img src="./images/7.png" alt="aio-yoga"></p>
<p>You can choose anything private address :</p>
<p><img src="./images/8.png" alt="aio-yoga">
<img src="./images/9.png" alt="aio-yoga"></p>
<h4 id="4-add-internal-network-to-router">4. Add internal network to router</h4>
<p>Back again to router menu, and add internal network on router like bellow :
<img src="./images/10.png" alt="aio-yoga">
<img src="./images/11.png" alt="aio-yoga">
Make sure network correct :</p>
<p><img src="./images/12.png" alt="aio-yoga"></p>
<h4 id="5--6-create-images--flavor">5 &amp; 6, Create images &amp; Flavor</h4>
<p>We use lightweight image with cirros</p>
<pre tabindex="0"><code>wget http://download.cirros-cloud.net/0.5.2/cirros-0.5.2-x86_64-disk.img
</code></pre><p><img src="./images/13.png" alt="aio-yoga"></p>
<p><strong>Create image</strong></p>
<pre tabindex="0"><code>openstack image create \
    --container-format bare \
    --disk-format qcow2 \
    --file cirros-0.5.2-x86_64-disk.img \
    cirros-img
</code></pre><p><strong>Create flavor</strong></p>
<pre tabindex="0"><code>openstack flavor create --ram 512  --vcpus 1 --disk 10 m1.tiny
</code></pre><p><img src="./images/14.png" alt="aio-yoga"></p>
<h4 id="7-create-instances">7. Create instances</h4>
<p><img src="./images/15.png" alt="aio-yoga"></p>
<p>add VM name
<img src="./images/16.png" alt="aio-yoga"></p>
<p>Chosse cirros image
<img src="./images/17.png" alt="aio-yoga"></p>
<p>Choose flavor
<img src="./images/18.png" alt="aio-yoga"></p>
<p>Choose internal network
<img src="./images/19.png" alt="aio-yoga"></p>
<p>Create new keypair or you can paste pubkey
<img src="./images/20.png" alt="aio-yoga"></p>
<h4 id="8-add-floating-ip">8. Add floating IP</h4>
<p>Click on instances, choose floating ip address</p>
<p><img src="./images/21.png" alt="aio-yoga">
<img src="./images/22.png" alt="aio-yoga"></p>
<p>For pool, you need use external network
<img src="./images/23.png" alt="aio-yoga"></p>
<p>Yeay, you already have floating IP
<img src="./images/24.png" alt="aio-yoga"></p>
<h4 id="9-create-security-group">9. Create security group</h4>
<p>security group like firewall, you can open or closed port, by default deny all, we need create first to open</p>
<p>Go to security groups menu</p>
<p><img src="./images/25.png" alt="aio-yoga"></p>
<p>Add rule for allow, bellow example allow all ICMP
<img src="./images/26.png" alt="aio-yoga"></p>
<p>allow all TCP (Only for test, better open by need)
<img src="./images/27.png" alt="aio-yoga"></p>
<h4 id="10-add-sg-to-instances">10. Add SG to instances</h4>
<p><img src="./images/28.png" alt="aio-yoga">
<img src="./images/29.png" alt="aio-yoga"></p>
<h4 id="11-verify-vm-connectivity">11. Verify VM connectivity</h4>
<p>Bellow you can see, we can access VM using Floating IP &amp; VM can ping to internet :)</p>
<p><img src="./images/30.png" alt="aio-yoga"></p>
<h2 id="thankyou">Thankyou</h2>
]]></content>
        </item>
        
        <item>
            <title>8. Deploy Magmacore on AWS with IaaS &#43; OpenStack for AGW (Lab) - Part1</title>
            <link>/posts/deploy-magmacore-on-aws-with-iaas-&#43;-openstack-for-agw-lab-part1/</link>
            <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
            
            <guid>/posts/deploy-magmacore-on-aws-with-iaas-&#43;-openstack-for-agw-lab-part1/</guid>
            <description>Specification : Amazon Web Services, Magmacore, 5G, Cloud, OpenStack, AGW, IaaS
Lab Diagram Summary steps Create VM Deployer (EC2) Install terraform &amp;amp; others depedencies Setup &amp;amp; Deploy Magma orchestrator Create AGW VM on openstack Install &amp;amp; connecting to Magma orchestrator Verify connected Prerequisites AWS Account Public Domain OpenStack cluster (optional) Can change using others platform (KVM, Virtualbox, or others.) A. Deploy Magma Orchestrator 1. Setup AWS IAM Create Users and use administrator permission access</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : Amazon Web Services, Magmacore, 5G, Cloud, OpenStack, AGW, IaaS</p>
</blockquote>
<h2 id="lab-diagram"><strong>Lab Diagram</strong></h2>
<p><img src="./images/aws-magma-diagram.png" alt="aws-lab"></p>
<p> 
 </p>
<hr>
<p> </p>
<h3 id="summary-steps"><strong>Summary steps</strong></h3>
<ul>
<li>Create VM Deployer (EC2)</li>
<li>Install terraform &amp; others depedencies</li>
<li>Setup &amp; Deploy Magma orchestrator</li>
<li>Create AGW VM on openstack</li>
<li>Install &amp; connecting to Magma orchestrator</li>
<li>Verify connected</li>
</ul>
<h3 id="prerequisites"><strong>Prerequisites</strong></h3>
<ul>
<li>AWS Account</li>
<li>Public Domain</li>
<li>OpenStack cluster (optional)
<ul>
<li>Can change using others platform (KVM, Virtualbox, or others.)</li>
</ul>
</li>
</ul>
<p> </p>
<h2 id="a-deploy-magma-orchestrator"><strong>A. Deploy Magma Orchestrator</strong></h2>
<h3 id="1-setup-aws-iam"><strong>1. Setup AWS IAM</strong></h3>
<p>Create Users and use <strong>administrator</strong> permission access</p>
<p><img src="./images/1.png" alt="magma-lab"></p>
<h3 id="2-deploy-terraform-ec2"><strong>2. Deploy terraform EC2</strong></h3>
<ul>
<li>VM for deployer you can use ec2 instances or directly from local access AWS IAM.</li>
<li>In this case, i am using ec2 because to make sure not have connection issue during deploy magma.</li>
</ul>
<p><img src="./images/2.png" alt="magma-lab"></p>
<p>Follow step like bellow, choose ubuntu 20.04
<img src="./images/3.png" alt="magma-lab"></p>
<p>Add your <strong>key-pair</strong> for access
<img src="./images/4.png" alt="magma-lab">
<img src="./images/5.png" alt="magma-lab"></p>
<p>Make sure you can access deployer VM
<img src="./images/6.png" alt="magma-lab"></p>
<h3 id="3-install-depedency"><strong>3. Install depedency</strong></h3>
<pre tabindex="0"><code>sudo apt update
sudo apt install python3-pip
sudo pip install boto3
</code></pre><h3 id="4-install-terraform"><strong>4. Install Terraform</strong></h3>
<p>Use version 1.0.11, tested in this lab</p>
<pre tabindex="0"><code>wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg
gpg --no-default-keyring --keyring /usr/share/keyrings/hashicorp-archive-keyring.gpg --fingerprint
echo &#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main&#34; | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update
sudo apt install terraform=1.0.11
</code></pre><p><img src="./images/7.png" alt="magma-lab"></p>
<h3 id="5-install-aws-cli--login"><strong>5. Install AWS CLI &amp; Login</strong></h3>
<pre tabindex="0"><code>cd ~
curl &#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&#34; -o &#34;awscliv2.zip&#34;
unzip awscliv2.zip
sudo ./aws/install
</code></pre><p><img src="./images/11.png" alt="magma-lab"></p>
<p>Login to your AWS Account using <strong>Access key &amp; secret key</strong>, you can download from when creating user above.</p>
<p><img src="./images/12.png" alt="magma-lab"></p>
<h3 id="6-preparation--assemble-certificates"><strong>6. Preparation &amp; Assemble Certificates</strong></h3>
<p>Clone Magma repository, choose branch and add environment variable <strong>(important)</strong></p>
<pre tabindex="0"><code>git clone https://github.com/magma/magma
git checkout -b v1.7.0
cd magma
export MAGMA_ROOT=/home/ubuntu/magma
</code></pre><p><img src="./images/8.png" alt="magma-lab"></p>
<h5 id="create--generate-secrets">Create &amp; generate secrets</h5>
<p>Make sure you have <strong>Public Domain (DNS)</strong> because later will use for connection between AGW &amp; Orchestrator</p>
<pre tabindex="0"><code>mkdir -p ~/secrets/certs
cd ~/secrets/certs

${MAGMA_ROOT}/orc8r/cloud/deploy/scripts/self_sign_certs.sh orc8r.rsch-lab.com
${MAGMA_ROOT}/orc8r/cloud/deploy/scripts/create_application_certs.sh orc8r.rsch-lab.com
</code></pre><p><img src="./images/9.png" alt="magma-lab"></p>
<p>And next create <code>admin_operator.pfx</code> for authentication to <strong>Magma API</strong></p>
<pre tabindex="0"><code>openssl pkcs12 -export -inkey admin_operator.key.pem -in admin_operator.pem -out admin_operator.pfx
ls -lah ~/secrets/certs/
</code></pre><p><img src="./images/10.png" alt="magma-lab"></p>
<h3 id="7-magma-orchestrator-installation"><strong>7. Magma orchestrator installation</strong></h3>
<p>We will use <code>Helm</code> for deploying orchestrator, go to examples directory, you can choose :</p>
<ul>
<li><strong>Blue-green</strong> = Build from scratch, you can custom anything</li>
<li><strong>POC</strong> = Build orchestrator with minimal specs (we choose this because limitation on credit)</li>
<li><strong>Remote</strong> = Store terraform state on S3 and locked by DyanamoDB Table</li>
<li><strong>Basic</strong> = Build with standar specification</li>
</ul>
<pre tabindex="0"><code>cd ${MAGMA_ROOT}/orc8r/cloud/deploy/terraform/orc8r-helm-aws/examples/
cd poc 
</code></pre><p><img src="./images/13.png" alt="magma-lab"></p>
<h5 id="edit-several-values">Edit several values</h5>
<p>You just configure values bellow :</p>
<ul>
<li><strong>Region orc8r</strong> = Your AWS Region will deploy</li>
<li><strong>EKS Cluster scaling</strong> = By default on POC use 8, but we increase to 12</li>
<li><strong>Orchestrator Domain</strong> = Using your public domain</li>
<li><strong>Region orc8r-app</strong> = Same with orc8r region</li>
<li><strong>Deployment type</strong> = You can use fwa, federated_fwa or all</li>
</ul>
<p><img src="./images/14.png" alt="magma-lab">
<img src="./images/14_1.png" alt="magma-lab">
<img src="./images/15.png" alt="magma-lab"></p>
<h5 id="deploy-orchestrator">Deploy orchestrator</h5>
<p>This difficult step, if any issue you can check first by <strong>terraform result</strong></p>
<pre tabindex="0"><code>terraform init 
terraform apply -target=module.orc8r
terraform apply -target=module.orc8r-app.null_resource.orc8r_seed_secrets
terraform apply
</code></pre><p><img src="./images/16.png" alt="magma-lab">
<img src="./images/17.png" alt="magma-lab">
<img src="./images/18.png" alt="magma-lab"></p>
<p>Make sure all terraform running <strong>smoothly</strong></p>
<p> </p>
<h5 id="install-kubectl"><strong>Install kubectl</strong></h5>
<p>Install for manages kubernetes cluster with CLI</p>
<pre tabindex="0"><code>sudo apt-get update
sudo apt-get install -y ca-certificates curl 
sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
echo &#34;deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main&#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt-get update
sudo apt-get install -y kubectl
</code></pre><p><img src="./images/kubectl.png" alt="magma-lab"></p>
<p>Change kubeconfig using <code>kubeconfig_orc8r</code> or you can move this one to <code>./kube/config</code></p>
<pre tabindex="0"><code>cd ${MAGMA_ROOT}/orc8r/cloud/deploy/terraform/orc8r-helm-aws/examples/poc
aws eks update-kubeconfig --name orc8r --region us-west-2
export KUBECONFIG=$(realpath kubeconfig_orc8r)
</code></pre><p><strong>Verify cluster EKS running</strong></p>
<pre tabindex="0"><code>kubectl get node
</code></pre><p><img src="./images/kubectl2.png" alt="magma-lab"></p>
<p><strong>Verify All POD Orchestrator running</strong></p>
<p><img src="./images/kubectl3.png" alt="magma-lab"></p>
<p><strong>Verify All Services Orchestrator</strong>
<img src="./images/kubectl4.png" alt="magma-lab"></p>
<h3 id="8-register-nameserver"><strong>8. Register nameserver</strong></h3>
<p>Register result of <strong>terraform output</strong> to your DNS Provider, like bellow :</p>
<p><img src="./images/dns.png" alt="magma-lab"></p>
<h3 id="9-pre-usages-orchestrator"><strong>9. Pre-usages Orchestrator</strong></h3>
<p>Before using magma orchestrator, we need follow guide bellow first :</p>
<h5 id="create-an-orchestrator-admin-user">Create an Orchestrator Admin User</h5>
<p>Just <strong>copy-paste</strong> no change anything</p>
<pre tabindex="0"><code>kubectl --namespace orc8r exec deploy/orc8r-orchestrator -- \
  /var/opt/magma/bin/accessc \
  add-existing -admin -cert /var/opt/magma/certs/admin_operator.pem \
  admin_operator
</code></pre><p>Verify success</p>
<pre tabindex="0"><code>kubectl --namespace orc8r exec deploy/orc8r-orchestrator -- \
  /var/opt/magma/bin/accessc list-certs
</code></pre><p><img src="./images/admin.png" alt="magma-lab"></p>
<h5 id="create-an-orchestrator-nms-user">Create an Orchestrator NMS User</h5>
<p>This user for access to Magma NMS GUI</p>
<p><strong>Format Create user</strong></p>
<pre tabindex="0"><code>kubectl --namespace orc8r exec -it deploy/nms-magmalte -- \
  yarn setAdminPassword &lt;ORGANIZATION&gt; &lt;USERNAME&gt; &lt;PASSWORD&gt;
</code></pre><p><strong>1. User for MAGMA-TEST organization</strong></p>
<pre tabindex="0"><code>kubectl --namespace orc8r exec -it deploy/nms-magmalte -- \
  yarn setAdminPassword magma-test admin-mgm passwordstrong
</code></pre><p><strong>2. User for MASTER organization</strong></p>
<pre tabindex="0"><code>kubectl --namespace orc8r exec -it deploy/nms-magmalte -- \
  yarn setAdminPassword master admin passwordstrong
</code></pre><p><img src="./images/nms.png" alt="magma-lab"></p>
<p> </p>
<h3 id="10-manages-nms-magma"><strong>10. Manages NMS Magma</strong></h3>
<p>First, you need login to your domain with format bellow :</p>
<pre tabindex="0"><code>https://organization-name.nms.yourdomain
</code></pre><p><img src="./images/login.png" alt="magma-lab"></p>
<h5 id="create-network">Create network</h5>
<p>After that we need create network, to add <strong>AGW</strong> Later, just follow like bellow :</p>
<p><img src="./images/network.png" alt="magma-lab"></p>
<p><img src="./images/network-create.png" alt="magma-lab"></p>
<p><strong>Let&rsquo;s go to network management</strong>
<img src="./images/network-create2.png" alt="magma-lab"></p>
<p>Bellow for user interface network management
<img src="./images/network2.png" alt="magma-lab"></p>
<p>Above last of <strong>Deploy magma orchestrator</strong> section, next is deploy Magma AGW on OpenStack</p>
<p> </p>
<hr>
<h2 id="b-deploy-magma-agw"><strong>B. Deploy Magma AGW</strong></h2>
<p>First, we need create VM or Instances with specs bellow :</p>
<ul>
<li>OS : Ubuntu 20.04</li>
<li>2 Network Interface :
<ul>
<li>eth0 = for <strong>SGi</strong> (internet connection, connection to Magma orc8r)</li>
<li>eth1 = for <strong>S1</strong> connection to eNodeB (SRSRAN)</li>
</ul>
</li>
</ul>
<p>In <strong>OpenStack</strong> we use external network for eth0, and internal for eth1</p>
<p> </p>
<h3 id="1-preparing-vm"><strong>1. Preparing VM</strong></h3>
<h5 id="create-instance">Create Instance</h5>
<p>For create instances you can follow my previous post</p>
<h5 id="create-s1-port">Create S1 Port</h5>
<p>You need create port inside of <strong>internal network</strong>, Network -&gt; Network -&gt; Chose internal network -&gt; Click Port and add port like bellow :</p>
<p><img src="./images/port.png" alt="magma-lab"></p>
<p>Add security groups, we use allow-all
<img src="./images/port2.png" alt="magma-lab"></p>
<p>After port created, go to <strong>instances</strong> and <strong>attach</strong> port S1
<img src="./images/port3.png" alt="magma-lab"></p>
<p>And you can see, VM already have 2 network interface
<img src="./images/port4.png" alt="magma-lab"></p>
<h5 id="access-instance">Access Instance</h5>
<p>Makesure network configuration like bellow</p>
<p><img src="./images/vm.png" alt="magma-lab"></p>
<p> </p>
<h3 id="2-installing-magma-agw"><strong>2. Installing Magma AGW</strong></h3>
<p>Note for this, we need change address like format bellow :</p>
<pre tabindex="0"><code>bash agw_install_ubuntu.sh IP_ADDRESS_SGi IP_GATEWAY
</code></pre><pre tabindex="0"><code>wget https://raw.githubusercontent.com/magma/magma/v1.6/lte/gateway/deploy/agw_install_ubuntu.sh
bash agw_install_ubuntu.sh 172.168.14.100/24 172.168.14.1
</code></pre><p><img src="./images/agw1.png" alt="magma-lab"></p>
<h5 id="notes--during-installation-magma-vm-will-rebooting-2-times-so-we-need-reconnect-ssh">Notes : During Installation, Magma VM will rebooting 2 times, so we need reconnect SSH</h5>
<p>After rebooting during installation, we can see <code>eth1</code> or S1 Interface interface already changed automatically
<img src="./images/agw2.png" alt="magma-lab"></p>
<p>To see <strong>progress</strong> installation, we can check using. And <code>Stopped AGW Installation</code> indicate success installation</p>
<pre tabindex="0"><code>journalctl -fu agw_installation
</code></pre><p><img src="./images/agw3.png" alt="magma-lab"></p>
<p><strong>To make sure installation success, check with</strong></p>
<pre tabindex="0"><code>sudo systemctl status magma@*
</code></pre><p><img src="./images/agw4.png" alt="magma-lab"></p>
<h3 id="3-configuring-agw"><strong>3. Configuring AGW</strong></h3>
<p>First, we need <strong>Prepare secrets &amp; control_proxy</strong> configuration</p>
<p>Create directory to plase certs configuration</p>
<pre tabindex="0"><code>sudo mkdir -p /var/opt/magma/tmp/certs/
sudo mkdir -p /var/opt/magma/configs
</code></pre><h5 id="download-secrets">Download secrets</h5>
<p>Download secrets from <strong>Magma Deployer</strong> VM previously created in step <code>6. Preparation &amp; Assemble Certificates</code></p>
<pre tabindex="0"><code>cd /var/opt/magma/tmp/certs/
sudo scp -i ~/priv-key-aws-tmp ubuntu@34.216.16.149:/home/ubuntu/secrets/certs/* .
ls
</code></pre><p><img src="./images/cagw1.png" alt="magma-lab"></p>
<h5 id="check-all-aws-route-53-address">Check all AWS Route 53 address</h5>
<p>Check on AWS Dashboard, Route 53 menu</p>
<p><img src="./images/53.png" alt="magma-lab"></p>
<h5 id="create-control_proxyyml">Create control_proxy.yml</h5>
<p>This file for connection from <strong>AGW to Magma orchestrator</strong> and save</p>
<pre tabindex="0"><code>sudo nano /var/opt/magma/configs/control_proxy.yml
</code></pre><pre tabindex="0"><code>cloud_address: controller.orc8r.rsch-lab.com
cloud_port: 443
bootstrap_address: bootstrapper-controller.orc8r.rsch-lab.com
bootstrap_port: 443
fluentd_address: fluentd.orc8r.rsch-lab.com
fluentd_port: 24224

rootca_cert: /var/opt/magma/tmp/certs/rootCA.pem
</code></pre><p><img src="./images/cagw2.png" alt="magma-lab"></p>
<h5 id="check-hardware-id--challenge-key">Check Hardware ID &amp; Challenge Key</h5>
<p>This one important, because will <strong>Register</strong> on the Magma orchestrator</p>
<pre tabindex="0"><code>show_gateway_info.py
</code></pre><p><img src="./images/key.png" alt="magma-lab"></p>
<h3 id="4-add--register-gateway"><strong>4. Add &amp; Register Gateway</strong></h3>
<p>We need login using magma-test organization like previous, and go to <strong>devices menu</strong> and <strong>add gateway</strong></p>
<p><img src="./images/gw1.png" alt="magma-lab"></p>
<p>Put Hardware ID &amp; Challenge Key
<img src="./images/gw2.png" alt="magma-lab"></p>
<p><strong>Just click next,</strong> for configuration soon when add eNodeb &amp; UE
<img src="./images/gw3.png" alt="magma-lab"></p>
<p><img src="./images/gw4.png" alt="magma-lab">
<img src="./images/gw5.png" alt="magma-lab">
<img src="./images/gw6.png" alt="magma-lab"></p>
<p><strong>Save and close</strong>
<img src="./images/gw7.png" alt="magma-lab"></p>
<h3 id="5-restarting-agw-services"><strong>5. Restarting AGW Services</strong></h3>
<pre tabindex="0"><code>sudo sytemctl stop magma@*
sudo systemctl restart magma@magmad.service
</code></pre><p><strong>Wait for a time, because need time connecting</strong>, After <strong>connected</strong> we can see like logs bellow :</p>
<p><img src="./images/gw8.png" alt="magma-lab"></p>
<h3 id="6-verify-on-nms"><strong>6. Verify on NMS</strong></h3>
<p>We can see AGW already connected from OpenStack VM to Magma orchestrator on AWS, and <strong>GOOD</strong> Health status.</p>
<p><img src="./images/gw9.png" alt="magma-lab">
<img src="./images/gw10.png" alt="magma-lab">
<img src="./images/gw11.png" alt="magma-lab"></p>
<h3 id="7-access-magma-api"><strong>7. Access Magma API</strong></h3>
<p>Othen than accessing using NMS, we can use API for manage.</p>
<h5 id="download-admin_operatorpfx">Download admin_operator.pfx</h5>
<p>You need download <code>admin_operator.pfx</code> from your magma orchestrator</p>
<p><img src="./images/fr.png" alt="magma-lab"></p>
<h5 id="import-certificates">Import certificates</h5>
<p>Use firefox for accessing WEB API, import certificates like bellow</p>
<p><img src="./images/fr1.png" alt="magma-lab"></p>
<p>Click <strong>Import</strong>, choose your previous downloaded
<img src="./images/fr2.png" alt="magma-lab"></p>
<h5 id="accessing-api">Accessing API</h5>
<p>Go to your address, or can check on Route 53 AWS</p>
<pre tabindex="0"><code>https://api.orc8r.rsch-lab.com/swagger/v1/ui/orchestrator
</code></pre><p><img src="./images/fr3.png" alt="magma-lab"></p>
<p>After it, you need refresh browser and <code>Accept risk and continue</code>, this issue happen because issuer <strong>unknown</strong> no problem, to <strong>solved</strong> this we can created secrets on magma installation using <strong>Lets encrypt</strong>.</p>
<p><img src="./images/fr4.png" alt="magma-lab">
<img src="./images/fr5.png" alt="magma-lab"></p>
<p> </p>
<h3 id="next-part-2--integrate-magma-agw-with-enodeb--ue-simulator-with-srsran"><strong>NEXT Part 2 : Integrate Magma AGW with eNodeB &amp; UE Simulator with srsRAN</strong></h3>
<p> </p>
<hr>
<h2 id="thankyou-to"><strong>Thankyou to</strong>:</h2>
<h6 id="--shubham-tatvamasihttpsgithubcomshubhamtatvamasi-for-great-documentation-from-you">- <a href="https://github.com/ShubhamTatvamasi">Shubham Tatvamasi</a> for great documentation from you</h6>
<h6 id="---magma-official-documentationhttpsdocsmagmacoreorgdocsbasicsintroductionhtml">-  <a href="https://docs.magmacore.org/docs/basics/introduction.html">Magma official Documentation</a></h6>
]]></content>
        </item>
        
        <item>
            <title>9. Integrate Magmacore with eNodeB &#43; UE Simulator (srsRAN) - Part2</title>
            <link>/posts/integrate-magmacore-with-enodeb-&#43;-ue-simulator-srsran-part2/</link>
            <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
            
            <guid>/posts/integrate-magmacore-with-enodeb-&#43;-ue-simulator-srsran-part2/</guid>
            <description>Specification : Amazon Web Services, Magmacore, 5G, Cloud, OpenStack, AGW, IaaS
Lab Diagram Will update soon immediately</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : Amazon Web Services, Magmacore, 5G, Cloud, OpenStack, AGW, IaaS</p>
</blockquote>
<h2 id="lab-diagram"><strong>Lab Diagram</strong></h2>
<p><img src="./images/aws-magma-diagram.png" alt="aws-lab"></p>
<p> 
 </p>
<hr>
<p> </p>
<p>Will update soon immediately</p>
]]></content>
        </item>
        
        <item>
            <title>10. Lab P4-INT (In-band network telemetry) using ONOS and eBPF</title>
            <link>/posts/lab-p4-int-in-band-network-telemetry-with-onos-from-scratch/</link>
            <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
            
            <guid>/posts/lab-p4-int-in-band-network-telemetry-with-onos-from-scratch/</guid>
            <description>Specification : In-band Network Telemetry, ONOS, P4, eBPF, XDP
Detailed Lab Diagram General Lab Diagram Summary steps Install all depedencies Install all packages needed Running ONOS Running Mininet with BMv2 Running INT Apps Running Parser, XDP &amp;amp; eBPF Adding Data to Grafana Verify System requirements Ubuntu 18.04 RAM = 8 GB (Prefer 16GB) vCPU = 4 (Prefer 8) Root user Preparation Make sure kernel &amp;amp; version of ubuntu like bellow, you can use above version, but bellow already tested.</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : In-band Network Telemetry, ONOS, P4, eBPF, XDP</p>
</blockquote>
<h2 id="detailed-lab-diagram"><strong>Detailed Lab Diagram</strong></h2>
<p><img src="./images/deep-p4-int.png" alt="aws-lab"></p>
<p> </p>
<h2 id="general-lab-diagram"><strong>General Lab Diagram</strong></h2>
<p><img src="./images/general-p4-int.png" alt="aws-lab"></p>
<p> 
 </p>
<hr>
<p> </p>
<h3 id="summary-steps"><strong>Summary steps</strong></h3>
<ul>
<li>Install all depedencies</li>
<li>Install all packages needed</li>
<li>Running ONOS</li>
<li>Running Mininet with BMv2</li>
<li>Running INT Apps</li>
<li>Running Parser, XDP &amp; eBPF</li>
<li>Adding Data to Grafana</li>
<li>Verify</li>
</ul>
<h3 id="system-requirements"><strong>System requirements</strong></h3>
<ul>
<li>Ubuntu 18.04</li>
<li>RAM = 8 GB (Prefer 16GB)</li>
<li>vCPU = 4 (Prefer 8)</li>
<li><strong>Root user</strong></li>
</ul>
<h3 id="preparation"><strong>Preparation</strong></h3>
<p>Make sure kernel &amp; version of <strong>ubuntu</strong> like bellow, you can use above version, but bellow already tested.</p>
<p><img src="./images/version.png" alt="p4-int"></p>
<h6 id="1-clone-repository">1. Clone repository</h6>
<pre tabindex="0"><code>sudo su
apt update
git clone https://github.com/opennetworkinglab/onos.git -b onos-2.1
</code></pre><h6 id="2-running-root-bootstrap">2. Running Root-bootstrap</h6>
<p>This activity will install automatically packages bellow :</p>
<ul>
<li>Installing all depedencies</li>
<li>creating sdn user</li>
<li>Installing bazel</li>
</ul>
<p>Make sure you already on root user, this command will finished until 20-30 minutes, let&rsquo;s create coffee first :)</p>
<p>Download root-bootstrap.sh here : <a href="https://github.com/assyafii/ONOS-P4-INT/blob/main/root-bootstrap.sh">https://github.com/assyafii/ONOS-P4-INT/blob/main/root-bootstrap.sh</a></p>
<pre tabindex="0"><code>cd /root/onos/tools/dev/p4vm
mv root-bootstrap.sh root-bootstrap.sh.bak 
sudo nano root-bootstrap.sh

Note : Copy &amp; paste from Github

bash root-bootstrap.sh
</code></pre><p>Makesure completed installation like bellow</p>
<p><img src="./images/root.png" alt="p4-int"></p>
<h6 id="3-running-user-bootstrap">3. Running User-bootstrap</h6>
<p>Then we continue to install all packages, user-bootstrap include :</p>
<ul>
<li>ONOS Apps</li>
<li>Mininet + BMv2</li>
<li>Build P4 Tools</li>
</ul>
<p>Download user-bootstrap.sh here : <a href="https://github.com/assyafii/ONOS-P4-INT/blob/main/user-bootstrap.sh">https://github.com/assyafii/ONOS-P4-INT/blob/main/user-bootstrap.sh</a></p>
<pre tabindex="0"><code>cd /root/onos/tools/dev/p4vm
mv user-bootstrap.sh user-bootstrap.sh.bak
sudo nano user-bootstrap.sh

Note : Copy &amp; paste from Github

su sdn &#39;user-bootstrap.sh&#39;
</code></pre><p>Makesure completed installation like bellow</p>
<p><img src="./images/user.png" alt="p4-int"></p>
<h6 id="4-build-onos">4. Build ONOS</h6>
<p>Take time for first time building, for second &amp; next will not</p>
<pre tabindex="0"><code>su sdn
cd ~/onos/
</code></pre><p>First, we need modified replace <strong>HTTP to HTTPS</strong>, this important, if you not follow this, installation <strong>will failed</strong>.</p>
<pre tabindex="0"><code>sed -i &#39;s/http:/https:/g&#39; ~/onos/tools/build/bazel/generate_workspace.bzl
sudo cat ~/onos/tools/build/bazel/generate_workspace.bzl | grep https:
bazel run onos-local clean
</code></pre><p><img src="./images/onos1.png" alt="p4-int"></p>
<p><strong>Open ONOS Dashboard using</strong></p>
<pre tabindex="0"><code>http://ip_onos:8181/onos/ui/index.html
</code></pre><pre tabindex="0"><code>user = onos
password = rocks
</code></pre><p><img src="./images/onos2.png" alt="p4-int">
<img src="./images/onos3.png" alt="p4-int"></p>
<p><strong>After verify, closed ONOS first, to continue activity</strong></p>
<p>In terminal press</p>
<pre tabindex="0"><code>CTRL + C
</code></pre><p><img src="./images/onos4.png" alt="p4-int"></p>
<h6 id="5-build-bcc-bpf-compiler-collection">5. Build BCC (BPF Compiler Collection)</h6>
<p>This activity will take time, ETA 30-60 minutes, enjoy with coffee first :)</p>
<pre tabindex="0"><code>sudo apt -y install bison build-essential cmake flex git libedit-dev libllvm3.9 llvm-3.9-dev libclang-3.9-dev python zlib1g-dev libelf-dev clang-3.9
wget https://github.com/iovisor/bcc/archive/refs/heads/tag_v0.7.0.zip
unzip tag_v0.7.0.zip
sudo mv bcc-tag_v0.7.0 bcc 
mkdir bcc/build; cd bcc/build
cmake .. -DCMAKE_INSTALL_PREFIX=/usr
make
sudo make install
</code></pre><p><img src="./images/bcc.png" alt="p4-int"></p>
<h6 id="6-download-bpf-collector">6. Download BPF Collector</h6>
<pre tabindex="0"><code>cd ~
git clone https://gitlab.com/tunv_ebpf/BPFCollector.git
cd BPFCollector
git checkout -t origin/spec_1.0
</code></pre><h6 id="7-activate-bpf--create-new-virtual-interface">7. Activate BPF &amp; Create new virtual interface</h6>
<p>This interface will used for parser, if you <strong>reboot</strong> VM later, you need add this interfaces again</p>
<pre tabindex="0"><code>sudo sysctl net/core/bpf_jit_enable=1
pip install cython
sudo ip link add veth_1 type veth peer name veth_2 
sudo ip link set dev veth_1 up 
sudo ip link set dev veth_2 up 
</code></pre><p><img src="./images/bpf_int.png" alt="p4-int"></p>
<h3 id="monitoring-section"><strong>Monitoring Section</strong></h3>
<h6 id="1-install-influxdb">1. Install InfluxDB</h6>
<pre tabindex="0"><code>sudo curl -sL https://repos.influxdata.com/influxdb.key | sudo apt-key add -
sudo echo &#34;deb https://repos.influxdata.com/ubuntu bionic stable&#34; | sudo tee /etc/apt/sources.list.d/influxdb.list
sudo apt update
sudo apt install influxdb
</code></pre><p>Make sure installation success.</p>
<pre tabindex="0"><code>sudo systemctl stop influxdb
sudo systemctl start influxdb
sudo systemctl enable --now influxdb
sudo systemctl is-enabled influxdb
sudo systemctl status influxdb
</code></pre><p><img src="./images/influx.png" alt="p4-int"></p>
<h6 id="testing-bpf-collector-connectivity">Testing BPF Collector connectivity</h6>
<p>Before continue installation, we test BPF first like bellow</p>
<pre tabindex="0"><code>sudo pip install influxdb

cd ~/BPFCollector
sudo pip install pytest
sudo python -m pytest 
</code></pre><p><strong>Make sure your connectivity green collor like bellow</strong></p>
<p><img src="./images/connect.png" alt="p4-int"></p>
<h6 id="2-install-prometheus">2. Install Prometheus</h6>
<pre tabindex="0"><code>cd ~
pip install prometheus-client
wget https://s3-eu-west-1.amazonaws.com/deb.robustperception.io/41EFC99D.gpg | sudo apt-key add -
sudo apt update
sudo apt -y install prometheus
sudo systemctl start prometheus
sudo systemctl enable prometheus
sudo systemctl status prometheus
</code></pre><p><img src="./images/prom.png" alt="p4-int"></p>
<h6 id="3-add-int-exporter-to-prometheus">3. Add INT exporter to Prometheus</h6>
<pre tabindex="0"><code>sudo nano /etc/prometheus/prometheus.yml
</code></pre><pre tabindex="0"><code>  - job_name: p4switch
    static_configs:
      - targets: [&#39;localhost:8000&#39;]
</code></pre><p><img src="./images/int-exporter.png" alt="p4-int"></p>
<p><strong>Save &amp; restart services</strong></p>
<pre tabindex="0"><code>sudo sytemctl restart prometheus
sudo sytemctl status prometheus
</code></pre><h6 id="4-install-grafana">4. Install Grafana</h6>
<pre tabindex="0"><code>nano grafana.sh
sudo apt-get install gnupg2 curl software-properties-common -y
curl https://packages.grafana.com/gpg.key | sudo apt-key add -
sudo add-apt-repository &#34;deb https://packages.grafana.com/oss/deb stable main&#34;
sudo apt-get update -y
sudo apt-get install grafana -y
sudo systemctl daemon-reload
sudo systemctl enable grafana-server
sudo systemctl start grafana-server
sudo systemctl status grafana-server
</code></pre><p><img src="./images/grafana.png" alt="p4-int"></p>
<p><strong>Access Grafana</strong>
Login with default credentials</p>
<pre tabindex="0"><code>http://your_ip:3000

username : admin
password : admin
</code></pre><p><img src="./images/gui.png" alt="p4-int"></p>
<h6 id="5-add-data-source">5. Add data source</h6>
<p><img src="./images/graf1.png" alt="p4-int"></p>
<p>Add prometheus data source
<img src="./images/graf2.png" alt="p4-int">
<img src="./images/graf3.png" alt="p4-int"></p>
<p>Make sure data source working
<img src="./images/graf4.png" alt="p4-int"></p>
<h3 id="update-bmv2-topology"><strong>Update BMv2 Topology</strong></h3>
<pre tabindex="0"><code>su sdn
cd ~
sudo nano $ONOS_ROOT/tools/test/topos/bmv2-demo.py
</code></pre><h6 id="1-add-intf-module">1. Add Intf module</h6>
<pre tabindex="0"><code>Intf
</code></pre><p><img src="./images/topo.png" alt="p4-int"></p>
<h6 id="2-add-virtual-interface">2. Add Virtual interface</h6>
<pre tabindex="0"><code>collectorIntf = Intf( &#39;veth_1&#39;, node=net.nameToNode[ &#34;s12&#34; ] )
</code></pre><p><img src="./images/topo2.png" alt="p4-int">
 </p>
<hr>
<p> </p>
<h3 id="running-onos-int-p4"><strong>Running ONOS-INT P4</strong></h3>
<p>This section you need open <strong>4 terminal</strong>, you can use <code>Tmux</code> for it or open <strong>4 Tab terminal</strong></p>
<h4 id="terminal-1-running-onos">Terminal 1 (Running ONOS)</h4>
<pre tabindex="0"><code>su sdn
cd ~/onos/
bazel run onos-local clean
</code></pre><p><img src="./images/run1.png" alt="p4-int"></p>
<p><strong>Activate ONOS application</strong></p>
<p>Then, open ONOS Dashboard &amp; activate application like bellow</p>
<p><strong>1. Reactive Forwarding</strong></p>
<p><img src="./images/fwd.png" alt="p4-int"></p>
<p><strong>2. Proxy ARP</strong></p>
<p><img src="./images/proxyarp.png" alt="p4-int"></p>
<p><strong>3. INT Dashboard</strong></p>
<p><img src="./images/int1.png" alt="p4-int"></p>
<p>Choose <strong>Yes</strong> for confirm</p>
<p><img src="./images/int2.png" alt="p4-int"></p>
<p>Yeay, your INT dashboard already activated
<img src="./images/int3.png" alt="p4-int"></p>
<h4 id="terminal-2-running-mininet-bmv2">Terminal 2 (Running Mininet-BMv2)</h4>
<pre tabindex="0"><code>su sdn
cd ~
sudo -E $ONOS_ROOT/tools/test/topos/bmv2-demo.py --onos-ip=127.0.0.1 --pipeconf-id=org.onosproject.pipelines.int
</code></pre><p><strong>NOTES : If first time running, have error like bellow, just enter <code>exit</code> &amp; Running again</strong>
<img src="./images/mn_error.png" alt="p4-int"></p>
<p><strong>Running Mininet again, until bellow</strong></p>
<p>Make sure ping connection success
<img src="./images/mn_ping.png" alt="p4-int"></p>
<h4 id="terminal-3-running-bpf-parser">Terminal 3 (Running BPF Parser)</h4>
<pre tabindex="0"><code>su sdn 
cd ~ 
sudo python BPFCollector/PTClient.py veth_2
</code></pre><p><img src="./images/bpf_parser.png" alt="p4-int"></p>
<h4 id="terminal-4-add-mirroring">Terminal 4 (Add mirroring)</h4>
<pre tabindex="0"><code>su sdn 
cd ~ 
simple_switch_CLI --thrift-port `cat /tmp/bmv2-s12-thrift-port`
</code></pre><pre tabindex="0"><code>mirroring_add 500 4
</code></pre><p><img src="./images/mirroring_add.png" alt="p4-int"></p>
<h6 id="note--to-get-value-4-above">Note : To get value <code>4</code> above</h6>
<p>You can check on onos dashboard like bellow :</p>
<p><img src="./images/ver1.png" alt="p4-int">
<img src="./images/ver2.png" alt="p4-int"></p>
<h4 id="back-to-terminal-2-generate-traffic">Back to terminal 2 (Generate traffic)</h4>
<ul>
<li><strong>H2</strong> = as a iperf server using UDP traffic (Port 5001)</li>
<li><strong>H1</strong> = as a iperf server, generate trafic to H2</li>
<li>You can customize how much traffic and others for iperf.</li>
</ul>
<pre tabindex="0"><code>h2 iperf -s -u &amp;
h1 iperf -c h2 -u -t 1000 -i 1 
</code></pre><p><img src="./images/iperf.png" alt="p4-int"></p>
<p> </p>
<hr>
<p> </p>
<h3 id="verify-network--add-int-flow-rule"><strong>Verify network &amp; add INT Flow (Rule)</strong></h3>
<h6 id="1-you-can-see-traffic-bellow">1. You can see traffic bellow</h6>
<p>Note : Press <strong>H</strong> to show host, &amp; triple <strong>L</strong> to show links</p>
<p><img src="./images/flow.png" alt="p4-int"></p>
<h6 id="2-add-int-collector">2. Add INT Collector</h6>
<p>By default using port <strong>54321</strong>, this can customize on PTCollector file</p>
<p><img src="./images/int_app1.png" alt="p4-int"></p>
<h6 id="3-add-int-flow-rule">3. Add INT flow (Rule)</h6>
<p>Add INT rule, in this case we will monitor protocol UDP Port 5001 from H1 to H2, <strong>so if any traffic on that, INT apps will add new INT header, you can see on Lab Detailed Diagram above</strong></p>
<p><img src="./images/int_app2.png" alt="p4-int"></p>
<h6 id="4-check-prometheus-status">4. Check prometheus status</h6>
<p><img src="./images/prometheus_switch.png" alt="p4-int"></p>
<h6 id="5-check-int-metrics">5. Check INT metrics</h6>
<p>Yeay :)</p>
<p><img src="./images/exporter.png" alt="p4-int"></p>
<h3 id="last-step-add-metrics-to-visualization"><strong>Last step, add metrics to visualization</strong></h3>
<p><strong>Add new panel</strong>
<img src="./images/viz1.png" alt="p4-int"></p>
<p><strong>Choose metrics name</strong>
<img src="./images/viz2.png" alt="p4-int"></p>
<p><strong>And you can see visualization :)</strong>
<img src="./images/viz3.png" alt="p4-int">
<img src="./images/viz4.png" alt="p4-int"></p>
<h4 id="video-guide">Video guide</h4>
<p>Section using 4 terminal is hard, you can see my video guide on youtube (video last 2 years, but same)</p>
<h4 id="thankyou">Thankyou</h4>
<p>Enjoy your lab &amp; Hopefully we can learning &amp; sharing.</p>
<p> </p>
<h4 id="reference">Reference</h4>
<ul>
<li><a href="https://www.sdnlab.com/24279.html">https://www.sdnlab.com/24279.html</a></li>
<li><a href="https://wiki.onosproject.org/display/ONOS/In-band+Network+Telemetry+%28INT%29+with+ONOS+and+P4">https://wiki.onosproject.org/display/ONOS/In-band+Network+Telemetry+%28INT%29+with+ONOS+and+P4</a></li>
<li><a href="https://github.com/opennetworkinglab/onos">https://github.com/opennetworkinglab/onos</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>11. Deploy OSM MANO &amp; Onboarding VNF in Openstack NFVi</title>
            <link>/posts/deploy-osm-mano-onboarding-vnf-in-openstsack-nfvi/</link>
            <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
            
            <guid>/posts/deploy-osm-mano-onboarding-vnf-in-openstsack-nfvi/</guid>
            <description>Specification : OpenStack, OSM, NFV, MANO, VNF Onboarding
NFV-MANO Lab Architecture Specs Value OS Ubuntu 20.04 vCPU 4 RAM 8GB Storage 40 GB Requirements Openstack environment (Check installation on http://luthfi.dev/docs/6.-install-openstack-aio-with-kolla-ansible-in-ubuntu/) Connectivity between Openstack &amp;amp; OSM Summary Steps Install OSM Add Openstack (NFVi) to OSM MANO via VIM Preparing images, network, keypair, security groups on openstack (day-0) Creating &amp;amp; Onboarding VNF Packages Verify &amp;amp; testing This my VM for OSM 1.</description>
            <content type="html"><![CDATA[<hr>
<blockquote>
<p>Specification : OpenStack, OSM, NFV, MANO, VNF Onboarding</p>
</blockquote>
<h2 id="nfv-mano-lab-architecture"><strong>NFV-MANO Lab Architecture</strong></h2>
<p><img src="./images/osm-nfv.png" alt="osm-lab"></p>
<p> </p>
<table>
<thead>
<tr>
<th style="text-align:center">Specs</th>
<th style="text-align:center">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">OS</td>
<td style="text-align:center">Ubuntu 20.04</td>
</tr>
<tr>
<td style="text-align:center">vCPU</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">RAM</td>
<td style="text-align:center">8GB</td>
</tr>
<tr>
<td style="text-align:center">Storage</td>
<td style="text-align:center">40 GB</td>
</tr>
</tbody>
</table>
<h3 id="requirements"><strong>Requirements</strong></h3>
<ol>
<li><strong>Openstack environment</strong> (Check installation on <a href="http://luthfi.dev/docs/6.-install-openstack-aio-with-kolla-ansible-in-ubuntu/">http://luthfi.dev/docs/6.-install-openstack-aio-with-kolla-ansible-in-ubuntu/</a>)</li>
<li><strong>Connectivity between Openstack &amp; OSM</strong></li>
</ol>
<p> </p>
<hr>
<p> </p>
<h3 id="summary-steps"><strong>Summary Steps</strong></h3>
<ol>
<li>Install OSM</li>
<li>Add Openstack (NFVi) to OSM MANO via VIM</li>
<li>Preparing images, network, keypair, security groups on openstack (day-0)</li>
<li>Creating &amp; Onboarding VNF Packages</li>
<li>Verify &amp; testing</li>
</ol>
<p> </p>
<h3 id="this-my-vm-for-osm"><strong>This my VM for OSM</strong></h3>
<p><img src="./images/vmku.png" alt="osm-lab"></p>
<h3 id="1-add-regular-user"><strong>1. Add regular user</strong></h3>
<p>If your VM not have regular/ubuntu user, please add first because for installation later.</p>
<pre tabindex="0"><code>adduser ubuntu
usermod -aG sudo ubuntu
su ubuntu
cd ~
</code></pre><p><img src="./images/user.png" alt="osm-lab"></p>
<h3 id="2-download--install-osm-packages"><strong>2. Download &amp; Install OSM Packages</strong></h3>
<p>This steps all packages will installed automatically with 1 command, and OSM Component running as container/POD on top off Kubernetes.</p>
<pre tabindex="0"><code>wget https://osm-download.etsi.org/ftp/osm-12.0-twelve/install_osm.sh
chmod +x install_osm.sh
./install_osm.sh 
</code></pre><p><strong>To continue installation, please press Y</strong>
This installation takes 15-20 minutes, let&rsquo;s drink coffee first hehe.</p>
<p><img src="./images/install.png" alt="osm-lab"></p>
<p>For more detail about optional installation, you can from official document : <a href="https://osm.etsi.org/docs/user-guide/latest/03-installing-osm.html">https://osm.etsi.org/docs/user-guide/latest/03-installing-osm.html</a></p>
<h3 id="3-verification-after-installation"><strong>3. Verification after installation</strong></h3>
<h4 id="installation-success"><strong>Installation success</strong></h4>
<p>Make sure your installation like bellow :</p>
<p><img src="./images/success.png" alt="osm-lab"></p>
<h4 id="pod-status"><strong>POD Status</strong></h4>
<pre tabindex="0"><code>kubectl get pod -A
kubectl get svc -A
</code></pre><p><img src="./images/pod.png" alt="osm-lab"></p>
<h4 id="osm-dashboard"><strong>OSM Dashboard</strong></h4>
<p>Open your OSM Dashboard with External IP from SVC, above steps.</p>
<p><img src="./images/dashboard1.png" alt="osm-lab">
<img src="./images/dashboard2.png" alt="osm-lab"></p>
<h3 id="4-open-your-openstack"><strong>4. Open Your Openstack</strong></h3>
<p>Before add Openstack to MANO, we need understand VIM URL (Openstack URL), in this case openstack using keystone/identity services using port 5000</p>
<pre tabindex="0"><code>Our VIM URL : http://172.12.12.254:5000/v3/
</code></pre><p><img src="./images/neutron.png" alt="osm-lab">
<img src="./images/neutron2.png" alt="osm-lab"></p>
<h3 id="5-add-openstack-nfvi-to-mano-vim"><strong>5. Add Openstack NFVi to MANO (VIM)</strong></h3>
<p><strong>VIM</strong> is one of MANO component, this function for handle nfvi like openstack, vmware, cloud, and others.</p>
<h4 id="add-openstack-to-vim-accounts-like-bellow">Add Openstack to VIM Accounts, like bellow:</h4>
<p><img src="./images/vim1.png" alt="osm-lab"></p>
<h4 id="write-about-your-openstack-nfvi-information">Write about your openstack (NFVi) information</h4>
<ol>
<li><strong>Name</strong> : your VIM Account name</li>
<li><strong>Type</strong> : Your NFVi type</li>
<li><strong>VIM URL</strong> : Your openstack keystone API, (check above)</li>
<li><strong>VIM Username</strong> : Your openstack user</li>
<li><strong>VIM Password</strong> : Your openstack password</li>
<li><strong>VIM Project/Tenant</strong> : Your openstack project will use for VNF</li>
<li><strong>Config</strong> : This section you need if you using HTTP for connection &amp; use floating IP for VNF management later.</li>
</ol>
<p><img src="./images/vim2.png" alt="osm-lab"></p>
<h4 id="make-sure-your-nfvi-connected-to-mano">Make sure your NFVi connected to MANO</h4>
<p><img src="./images/vim3.png" alt="osm-lab"></p>
<h3 id="6-preparing-openstack-environment-day-0"><strong>6. Preparing openstack environment (Day-0)</strong></h3>
<p>This section we prepared first images &amp; network. Actually depends from your <strong>VNF Packages</strong> will use <strong>existing</strong> resources (network, keypair) or <strong>created new</strong> one.</p>
<h4 id="a-internal-network">A. Internal Network</h4>
<p>In this case, we create new internal network named <strong>mgmt</strong> for network management VNF &amp; use <strong>floating IP</strong> for external connection, need connect to external network with <strong>router</strong>.</p>
<p><img src="./images/mgmt.png" alt="osm-lab"></p>
<h4 id="b-images">B. Images</h4>
<p><img src="./images/images.png" alt="osm-lab"></p>
<h4 id="c-security-groups">C. Security Groups</h4>
<p><img src="./images/securityg.png" alt="osm-lab"></p>
<hr>
<p> </p>
<h3 id="understanding-about-vnf--ns-packages-in-this-lab"><strong>Understanding about VNF &amp; NS Packages in this Lab</strong></h3>
<p><img src="./images/vnfd.png" alt="osm-lab"></p>
<p>Create <strong>VNF &amp; NS Packages</strong> is preety complex to understand, because here named of VM (Virtual Machines) not a VNF again but vDU
(Deployment Unit) &amp; others complex term.</p>
<p>So to simply this, we created <strong>simple VNF Packages</strong> with 1 vDU (VM), and <strong>create NS Packages</strong> (Network service) for connect <strong>eth0</strong> to mgmt network &amp; <strong>eth1</strong> to inside network.</p>
<h4 id="meaning">Meaning</h4>
<ol>
<li><strong>vDPU</strong> (Virtual Deployment Unit)</li>
<li><strong>VNFD</strong> (Virtual Network Function Descriptor)</li>
<li><strong>NSD</strong> (Network Service Descriptor)</li>
<li><strong>VLD</strong> (Virtual Link Descriptor)</li>
<li><strong>CP</strong> (Connection Point)</li>
<li><strong>ICP &amp; ECP</strong> (I=Internal, E=External)</li>
<li><strong>NST</strong> (Network Slice Template)</li>
<li>And many more.</li>
</ol>
<p>If you interest to understand more about VNFD, NSD &amp; NST you can check on official OSM : <a href="https://osm.etsi.org/docs/user-guide/latest/05-osm-usage.html">https://osm.etsi.org/docs/user-guide/latest/05-osm-usage.html</a></p>
<p> </p>
<hr>
<h3 id="7-upload-vnf-packages"><strong>7. Upload VNF Packages</strong></h3>
<p>Download simple VNF Packages <strong>here</strong> : <a href="https://github.com/assyafii/vnf-example-packages">https://github.com/assyafii/vnf-example-packages</a></p>
<h4 id="first-upload-vnf-packages">First, upload VNF packages</h4>
<p><img src="./images/vnf.png" alt="osm-lab"></p>
<h4 id="then-upload-ns-packages">Then, upload NS packages</h4>
<p><img src="./images/ns.png" alt="osm-lab"></p>
<h3 id="8-onboarding-packages"><strong>8. Onboarding Packages</strong></h3>
<p>Just click instantiate, OSM Will created VM &amp; Others from packages.</p>
<p><img src="./images/instantiate.png" alt="osm-lab"></p>
<h4 id="choose-your-vim-accounts-will-deployed">Choose your VIM Accounts will deployed</h4>
<p><img src="./images/instantiate2.png" alt="osm-lab"></p>
<h4 id="wait-for-it">Wait for it</h4>
<p><img src="./images/onboarding_wait.png" alt="osm-lab"></p>
<h4 id="yeay-vnf--ns-success-onboarding">Yeay, VNF &amp; NS Success onboarding</h4>
<p><img src="./images/onboarding_success.png" alt="osm-lab"></p>
<h3 id="9-verification"><strong>9. Verification</strong></h3>
<p>This step you can verify from NFVi (Openstack) side</p>
<h4 id="you-can-see-here-vnf-already-created--have-floating-ip">You can see here, VNF Already created &amp; have Floating IP</h4>
<p><img src="./images/openstack_verify.png" alt="osm-lab"></p>
<h4 id="ns-already-created-also">NS Already created also</h4>
<p><img src="./images/openstack_network.png" alt="osm-lab"></p>
<h4 id="you-can-access-using-floating-ip--password-used-cloud_initcfg-defined-before-in-vnfd">You can access using Floating IP &amp; Password used cloud_init.cfg defined before in vnfd</h4>
<p><img src="./images/openstack_access.png" alt="osm-lab"></p>
<h3 id="all-official-packages"><strong>All Official Packages</strong></h3>
<p>You can check all references packages (VNFD, NSD, NST) here for use cases :</p>
<p><a href="https://osm.etsi.org/gitlab/vnf-onboarding/osm-packages">https://osm.etsi.org/gitlab/vnf-onboarding/osm-packages</a></p>
<h3 id="references"><strong>References</strong></h3>
<ul>
<li><a href="https://osm.etsi.org/docs/user-guide/latest/">https://osm.etsi.org/docs/user-guide/latest/</a></li>
<li><a href="https://codilime.com/blog/how-to-configure-vnfs-using-a-virtual-network-function-descriptor/">https://codilime.com/blog/how-to-configure-vnfs-using-a-virtual-network-function-descriptor/</a></li>
</ul>
]]></content>
        </item>
        
    </channel>
</rss>
